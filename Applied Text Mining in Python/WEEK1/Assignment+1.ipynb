{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_You are currently looking at **version 1.1** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-text-mining/resources/d9pwm) course resource._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "In this assignment, you'll be working with messy medical data and using regex to extract relevant infromation from the data. \n",
    "\n",
    "Each line of the `dates.txt` file corresponds to a medical note. Each note has a date that needs to be extracted, but each date is encoded in one of many formats.\n",
    "\n",
    "The goal of this assignment is to correctly identify all of the different date variants encoded in this dataset and to properly normalize and sort the dates. \n",
    "\n",
    "Here is a list of some of the variants you might encounter in this dataset:\n",
    "* 04/20/2009; 04/20/09; 4/20/09; 4/3/09\n",
    "* Mar-20-2009; Mar 20, 2009; March 20, 2009;  Mar. 20, 2009; Mar 20 2009;\n",
    "* 20 Mar 2009; 20 March 2009; 20 Mar. 2009; 20 March, 2009\n",
    "* Mar 20th, 2009; Mar 21st, 2009; Mar 22nd, 2009\n",
    "* Feb 2009; Sep 2009; Oct 2010\n",
    "* 6/2008; 12/2009\n",
    "* 2009; 2010\n",
    "\n",
    "Once you have extracted these date patterns from the text, the next step is to sort them in ascending chronological order accoring to the following rules:\n",
    "* Assume all dates in xx/xx/xx format are mm/dd/yy\n",
    "* Assume all dates where year is encoded in only two digits are years from the 1900's (e.g. 1/5/89 is January 5th, 1989)\n",
    "* If the day is missing (e.g. 9/2009), assume it is the first day of the month (e.g. September 1, 2009).\n",
    "* If the month is missing (e.g. 2010), assume it is the first of January of that year (e.g. January 1, 2010).\n",
    "* Watch out for potential typos as this is a raw, real-life derived dataset.\n",
    "\n",
    "With these rules in mind, find the correct date in each note and return a pandas Series in chronological order of the original Series' indices.\n",
    "\n",
    "For example if the original series was this:\n",
    "\n",
    "    0    1999\n",
    "    1    2010\n",
    "    2    1978\n",
    "    3    2015\n",
    "    4    1985\n",
    "\n",
    "Your function should return this:\n",
    "\n",
    "    0    2\n",
    "    1    4\n",
    "    2    0\n",
    "    3    1\n",
    "    4    3\n",
    "\n",
    "Your score will be calculated using [Kendall's tau](https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient), a correlation measure for ordinal data.\n",
    "\n",
    "*This function should return a Series of length 500 and dtype int.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calendar\n",
    "import re\n",
    "doc = []\n",
    "with open('dates.txt') as file:\n",
    "    for line in file:\n",
    "        doc.append(line)\n",
    "\n",
    "df = pd.Series(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#125 out of 500: only included mm/dd/yy , mm/dd/yyyy , mm-dd-yyyy ,  mm-dd-yy (range:0~124, length:125)\n",
    "##Accumulated Total:125\n",
    "df_num = df.str.extractall(r'(?P<MM>\\b\\d{1,2})[/-](?P<DD>\\d{1,2})[/-](?P<YYYY>\\d{2,4}\\b)')\n",
    "df_num['dx'] = df_num.index.get_level_values(0)\n",
    "df_num = df_num.astype(int)\n",
    "def nin(row):\n",
    "    if(row<100):\n",
    "        return row+1900\n",
    "    else:\n",
    "        return row\n",
    "df_num['YYYY'] = df_num['YYYY'].map(nin)\n",
    "#69 out of 500: only included dd Month yyyy, dd mon yyyy, dd mon. yyyy, dd month, yyyy (range:125~193, length:69)\n",
    "##Accumulated Total:194\n",
    "## Drop the first column since the first and second columns are duplicated (they are completely same)\n",
    "df_eu=df.str.extractall(r'(?P<DD>\\s?\\d{1,2}[-|.|\\s|th|st|nd])\\s?((?P<MM>Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*[-|\\s|.|,])(?P<YYYY>\\s?\\d{2,4})').drop(1,1)\n",
    "df_eu = df_eu[['MM','DD','YYYY']]\n",
    "\n",
    "def month_to_num(row):\n",
    "    dicc = {v:k for k,v in enumerate(calendar.month_abbr)}\n",
    "    return dicc[row]\n",
    "df_eu['MM'] = df_eu['MM'].map(month_to_num)\n",
    "df_eu['dx'] = df_eu.index.get_level_values(0)\n",
    "df_eu = df_eu.astype(int)\n",
    "\n",
    "#34 out of 500:only included mm-dd-yyyy, mm dd, yyyy, mon dd, yyyy, mm. dd, yyyy, mm dd yyyy (range:194~227, length:34)\n",
    "##Accumulated Total:228\n",
    "df_us=df.str.extractall(r'\\s?((?P<MM>Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*[-|\\s|.|,])(?P<DD>\\s?\\d{1,2}.{1,2}[,|\\s|-])\\s?(?P<YYYY>\\d{2,4})').drop(0,1)\n",
    "df_us['DD'] = df_us['DD'].str.replace(r'[,\\s]',\"\")\n",
    "df_us['MM'] = df_us[\"MM\"].map(month_to_num)\n",
    "df_us['dx'] = df_us.index.get_level_values(0)\n",
    "df_us = df_us.astype(int)\n",
    "\n",
    "#114 out of 500: only included mon yyyy (range:228~342, length:102)\n",
    "##Accumulated Total:342\n",
    "df_short_us = df.str.extractall(r'((?P<MM>Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*\\s?(?P<YYYY>\\d{4}))').drop(0,1)\n",
    "##Since there is no day in original dataset, all the day columns are considered the first day of the month \n",
    "df_short_us['DD'] = 1\n",
    "df_short_us = df_short_us[['MM','DD','YYYY']]\n",
    "df_short_us = df_short_us[(228,0):]\n",
    "df_short_us['MM'] = df_short_us['MM'].map(month_to_num)\n",
    "df_short_us['dx'] = df_short_us.index.get_level_values(0)\n",
    "df_short_us = df_short_us.astype(int)\n",
    "\n",
    "#112 out of 500: m/yyyy, mm/yyyy (range:343~454, length: 112)\n",
    "##(A lot of rows from the beginning are duplicated with df_num so subtract the duplicated rows in df_num)\n",
    "##Accumulated Total:454\n",
    "df_short_num = df.str.extractall((r'\\s?(?P<MM>\\d{1,2}/)(?P<DD>)\\s?(?P<YYYY>\\d{4})'))\n",
    "##Convert the type of the column 'MM' to integer since in order to confirm the month that must be less than 12\n",
    "df_short_num['MM'] = df_short_num['MM'].str.replace('/',\"\").astype(int)\n",
    "df_short_num = df_short_num[(343,0):]\n",
    "df_short_num['DD'] = 1\n",
    "df_short_num = df_short_num.astype(int)\n",
    "\n",
    "####### not compeletely sure about the accuracy of the result ##########\n",
    "#45 out of 500: YYYY(range:455~499, length: 45)\n",
    "## Assume the year without the month, January 1st.\n",
    "df_year = df.str.extractall(r'(?P<MM>)(?P<DD>)(?P<YYYY>[^\\d/-][012]\\d{3}|^[012]\\d{3})')\n",
    "df_year['YYYY'] = df_year['YYYY'].str.replace(r'[syr~\\(.]',\"\").astype(int)\n",
    "df_year[['MM','DD']] = 1\n",
    "df_year = df_year[(455,0):]\n",
    "df_year = df_year.astype(int)\n",
    "\n",
    "for dff in [df_short_num,df_year]:\n",
    "    dff['dx'] = dff.index.get_level_values(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Currently on Zoloft, 50 mg, Dicolenac, 100 mg, Hydrocodone, Seroquel, 100 mg. Was hospitalized for Serotonin Syndrome for 3 days in March, 2005 due to Dr. Potts increasing effexor and zoloft. Current Psychopharmacologist(s) and Phone #(s):\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[339]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Combine dataframes\n",
    "df_united = df_num.append([df_eu,df_us,df_short_us,df_short_num,df_year])\n",
    "df_united.drop(1,level='match',inplace=True,axis=0)\n",
    "df_united.reset_index(inplace=True)\n",
    "df_united.drop(['level_0','match'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missed part fixing process\n",
    "#Total:14\n",
    "miss_list = []\n",
    "for i in range(500):\n",
    "    if i not in list(df_united['dx']):\n",
    "        miss_list.append(i)\n",
    "#print('list of index missed:',miss_list) \n",
    "\n",
    "miss_df = df[miss_list]\n",
    "\n",
    "#regular exp\n",
    "case1_miss = miss_df.str.extractall(r'[^\\d][\\s](?P<MM>Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*[,]\\s(?P<DD>)(?P<YYYY>[12]\\d{3})')\n",
    "case2_miss = miss_df.str.extractall(r'^(?P<MM>Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*[,]\\s(?P<DD>)(?P<YYYY>[12]\\d{3})')\n",
    "case3_miss = miss_df.str.extractall(r'(?P<DD>[\\d])(?P<MM>Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*[,]\\s(?P<YYYY>[12]\\d{3})')\n",
    "case3_miss = case3_miss[['MM','DD','YYYY']]\n",
    "case4_miss = miss_df.str.extractall(r'(?P<MM>[0]\\d{1,2})[/](?P<DD>\\d{2})[/](?P<YYYY>\\d{2})').astype(int)\n",
    "\n",
    "#create index columns, convert month to int. \n",
    "for dfs in [case1_miss,case2_miss,case3_miss,case4_miss]:\n",
    "    dfs['dx'] = dfs.index.get_level_values(0)\n",
    "    \n",
    "    if dfs['MM'].dtype != int:\n",
    "        dfs['MM'] = dfs['MM'].map(month_to_num)\n",
    "    \n",
    "    dfs['DD'].replace(np.nan,1,inplace=True)\n",
    "        \n",
    "#Since the function 'astype' doesn't work so manually convert the whole dataframe into integer type.\n",
    "case1_miss = case1_miss.astype(int)\n",
    "case2_miss = case2_miss.astype(int)\n",
    "case3_miss = case3_miss.astype(int)\n",
    "case4_miss = case4_miss.astype(int)\n",
    "\n",
    "#Change the type 'YY -> 'YYYY'\n",
    "case4_miss['YYYY'] = case4_miss['YYYY'] + 1900\n",
    "\n",
    "#combine all the cases, reset the multilevel index to single\n",
    "miss_united = case1_miss.append([case2_miss,case3_miss,case4_miss])\n",
    "miss_united.reset_index(inplace=True)\n",
    "miss_united.drop(['level_0','match'],1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel/__main__.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "united = df_united.append(miss_united)\n",
    "united.reset_index(inplace=True)\n",
    "united.drop('index',1,inplace=True)\n",
    "united = united.astype(str)\n",
    "#united.apply()\n",
    "def alla(row):\n",
    "    row['all'] = row['MM']+'/'+row['DD'] +'/'+row['YYYY']\n",
    "    return row\n",
    "\n",
    "united = united.apply(alla,axis=1)\n",
    "united_all = united[['all','dx']]\n",
    "united_all['all'] = pd.to_datetime(united_all['all'])\n",
    "\n",
    "#df['Date'] =pd.to_datetime(df.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dx\n",
       "0      9\n",
       "1     84\n",
       "2      2\n",
       "3     53\n",
       "4     28\n",
       "5    474\n",
       "6    153\n",
       "7     13\n",
       "8    129\n",
       "9     98\n",
       "10   111\n",
       "11   225\n",
       "12    31\n",
       "13   171\n",
       "14   191\n",
       "15   486\n",
       "16   415\n",
       "17   335\n",
       "18    36\n",
       "19   405\n",
       "20   323\n",
       "21   422\n",
       "22   375\n",
       "23   380\n",
       "24   345\n",
       "25    57\n",
       "26   481\n",
       "27   436\n",
       "28   104\n",
       "29   299\n",
       "..   ...\n",
       "470  220\n",
       "471  243\n",
       "472  208\n",
       "473  139\n",
       "474  320\n",
       "475  383\n",
       "476  244\n",
       "477  286\n",
       "478  480\n",
       "479  431\n",
       "480  279\n",
       "481  198\n",
       "482  381\n",
       "483  463\n",
       "484  366\n",
       "485  439\n",
       "486  255\n",
       "487  401\n",
       "488  475\n",
       "489  257\n",
       "490  152\n",
       "491  235\n",
       "492  464\n",
       "493  253\n",
       "494  231\n",
       "495  427\n",
       "496  141\n",
       "497  186\n",
       "498  161\n",
       "499  413\n",
       "\n",
       "[500 rows x 1 columns]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "united_all = united_all.sort_values(by='all')\n",
    "answer = united_all['dx'].astype(int).reset_index().drop('index',1)\n",
    "answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def date_sorter():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import calendar\n",
    "    import re\n",
    "    doc = []\n",
    "    with open('dates.txt') as file:\n",
    "        for line in file:\n",
    "            doc.append(line)\n",
    "\n",
    "    df = pd.Series(doc)    \n",
    "#125 out of 500: only included mm/dd/yy , mm/dd/yyyy , mm-dd-yyyy ,  mm-dd-yy (range:0~124, length:125)\n",
    "##Accumulated Total:125\n",
    "    df_num = df.str.extractall(r'(?P<MM>\\b\\d{1,2})[/-](?P<DD>\\d{1,2})[/-](?P<YYYY>\\d{2,4}\\b)')\n",
    "    df_num['dx'] = df_num.index.get_level_values(0)\n",
    "    df_num = df_num.astype(int)\n",
    "    def nin(row):\n",
    "        if(row<100):\n",
    "            return row+1900\n",
    "        else:\n",
    "            return row\n",
    "    df_num['YYYY'] = df_num['YYYY'].map(nin)\n",
    "#69 out of 500: only included dd Month yyyy, dd mon yyyy, dd mon. yyyy, dd month, yyyy (range:125~193, length:69)\n",
    "##Accumulated Total:194\n",
    "## Drop the first column since the first and second columns are duplicated (they are completely same)\n",
    "    df_eu=df.str.extractall(r'(?P<DD>\\s?\\d{1,2}[-|.|\\s|th|st|nd])\\s?((?P<MM>Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*[-|\\s|.|,])(?P<YYYY>\\s?\\d{2,4})').drop(1,1)\n",
    "    df_eu = df_eu[['MM','DD','YYYY']]\n",
    "\n",
    "    def month_to_num(row):\n",
    "        dicc = {v:k for k,v in enumerate(calendar.month_abbr)}\n",
    "        return dicc[row]\n",
    "    df_eu['MM'] = df_eu['MM'].map(month_to_num)\n",
    "    df_eu['dx'] = df_eu.index.get_level_values(0)\n",
    "    df_eu = df_eu.astype(int)\n",
    "\n",
    "#34 out of 500:only included mm-dd-yyyy, mm dd, yyyy, mon dd, yyyy, mm. dd, yyyy, mm dd yyyy (range:194~227, length:34)\n",
    "##Accumulated Total:228\n",
    "    df_us=df.str.extractall(r'\\s?((?P<MM>Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*[-|\\s|.|,])(?P<DD>\\s?\\d{1,2}.{1,2}[,|\\s|-])\\s?(?P<YYYY>\\d{2,4})').drop(0,1)\n",
    "    df_us['DD'] = df_us['DD'].str.replace(r'[,\\s]',\"\")\n",
    "    df_us['MM'] = df_us[\"MM\"].map(month_to_num)\n",
    "    df_us['dx'] = df_us.index.get_level_values(0)\n",
    "    df_us = df_us.astype(int)\n",
    "\n",
    "#114 out of 500: only included mon yyyy (range:228~342, length:102)\n",
    "##Accumulated Total:342\n",
    "    df_short_us = df.str.extractall(r'((?P<MM>Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*\\s?(?P<YYYY>\\d{4}))').drop(0,1)\n",
    "##Since there is no day in original dataset, all the day columns are considered the first day of the month \n",
    "    df_short_us['DD'] = 1\n",
    "    df_short_us = df_short_us[['MM','DD','YYYY']]\n",
    "    df_short_us = df_short_us[(228,0):]\n",
    "    df_short_us['MM'] = df_short_us['MM'].map(month_to_num)\n",
    "    df_short_us['dx'] = df_short_us.index.get_level_values(0)\n",
    "    df_short_us = df_short_us.astype(int)\n",
    "\n",
    "#112 out of 500: m/yyyy, mm/yyyy (range:343~454, length: 112)\n",
    "##(A lot of rows from the beginning are duplicated with df_num so subtract the duplicated rows in df_num)\n",
    "##Accumulated Total:454\n",
    "    df_short_num = df.str.extractall((r'\\s?(?P<MM>\\d{1,2}/)(?P<DD>)\\s?(?P<YYYY>\\d{4})'))\n",
    "##Convert the type of the column 'MM' to integer since in order to confirm the month that must be less than 12\n",
    "    df_short_num['MM'] = df_short_num['MM'].str.replace('/',\"\").astype(int)\n",
    "    df_short_num = df_short_num[(343,0):]\n",
    "    df_short_num['DD'] = 1\n",
    "    df_short_num = df_short_num.astype(int)\n",
    "\n",
    "####### not compeletely sure about the accuracy of the result ##########\n",
    "#45 out of 500: YYYY(range:455~499, length: 45)\n",
    "## Assume the year without the month, January 1st.\n",
    "    df_year = df.str.extractall(r'(?P<MM>)(?P<DD>)(?P<YYYY>[^\\d/-][012]\\d{3}|^[012]\\d{3})')\n",
    "    df_year['YYYY'] = df_year['YYYY'].str.replace(r'[syr~\\(.]',\"\").astype(int)\n",
    "    df_year[['MM','DD']] = 1\n",
    "    df_year = df_year[(455,0):]\n",
    "    df_year = df_year.astype(int)\n",
    "\n",
    "    for dff in [df_short_num,df_year]:\n",
    "        dff['dx'] = dff.index.get_level_values(0)\n",
    "    \n",
    "#Combine dataframes\n",
    "    df_united = df_num.append([df_eu,df_us,df_short_us,df_short_num,df_year])\n",
    "    df_united.drop(1,level='match',inplace=True,axis=0)\n",
    "    df_united.reset_index(inplace=True)\n",
    "    df_united.drop(['level_0','match'],axis=1,inplace=True)\n",
    "#missed part fixing process\n",
    "#Total:14\n",
    "    miss_list = []\n",
    "    for i in range(500):\n",
    "        if i not in list(df_united['dx']):\n",
    "            miss_list.append(i)\n",
    "    #print('list of index missed:',miss_list) \n",
    "\n",
    "    miss_df = df[miss_list]\n",
    "\n",
    "#regular exp\n",
    "    case1_miss = miss_df.str.extractall(r'[^\\d][\\s](?P<MM>Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*[,]\\s(?P<DD>)(?P<YYYY>[12]\\d{3})')\n",
    "    case2_miss = miss_df.str.extractall(r'^(?P<MM>Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*[,]\\s(?P<DD>)(?P<YYYY>[12]\\d{3})')\n",
    "    case3_miss = miss_df.str.extractall(r'(?P<DD>[\\d])(?P<MM>Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*[,]\\s(?P<YYYY>[12]\\d{3})')\n",
    "    case3_miss = case3_miss[['MM','DD','YYYY']]\n",
    "    case4_miss = miss_df.str.extractall(r'(?P<MM>[0]\\d{1,2})[/](?P<DD>\\d{2})[/](?P<YYYY>\\d{2})').astype(int)\n",
    "\n",
    "#create index columns, convert month to int. \n",
    "    for dfs in [case1_miss,case2_miss,case3_miss,case4_miss]:\n",
    "        dfs['dx'] = dfs.index.get_level_values(0)\n",
    "\n",
    "        if dfs['MM'].dtype != int:\n",
    "            dfs['MM'] = dfs['MM'].map(month_to_num)\n",
    "\n",
    "        dfs['DD'].replace(np.nan,1,inplace=True)\n",
    "\n",
    "#Since the function 'astype' doesn't work so manually convert the whole dataframe into integer type.\n",
    "    case1_miss = case1_miss.astype(int)\n",
    "    case2_miss = case2_miss.astype(int)\n",
    "    case3_miss = case3_miss.astype(int)\n",
    "    case4_miss = case4_miss.astype(int)\n",
    "\n",
    "#Change the type 'YY -> 'YYYY'\n",
    "    case4_miss['YYYY'] = case4_miss['YYYY'] + 1900\n",
    "\n",
    "#combine all the cases, reset the multilevel index to single\n",
    "    miss_united = case1_miss.append([case2_miss,case3_miss,case4_miss])\n",
    "    miss_united.reset_index(inplace=True)\n",
    "    miss_united.drop(['level_0','match'],1,inplace=True)\n",
    "    united = df_united.append(miss_united)\n",
    "    united.reset_index(inplace=True)\n",
    "    united.drop('index',1,inplace=True)\n",
    "    united = united.astype(str)\n",
    "#combine all the columns and make the full date type \n",
    "    def alla(row):\n",
    "        row['all'] = row['MM']+'/'+row['DD'] +'/'+row['YYYY']\n",
    "        return row\n",
    "\n",
    "    united = united.apply(alla,axis=1)\n",
    "\n",
    "#seperate the two columns for converting the type to datetime in order to sort in ascending order.\n",
    "    united_all = united[['all','dx']]\n",
    "    united_all['all'] = pd.to_datetime(united_all['all'])\n",
    "    united_all = united_all.sort_values(by='all')\n",
    "    answer = united_all['dx'].astype(int).reset_index().drop('index',1)\n",
    "    answer\n",
    "\n",
    "    return answer.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-text-mining",
   "graded_item_id": "LvcWI",
   "launcher_item_id": "krne9",
   "part_id": "Mkp1I"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
