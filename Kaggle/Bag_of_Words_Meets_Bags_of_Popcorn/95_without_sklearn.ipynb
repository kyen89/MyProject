{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re # 정규표현식을 사용해 텍스트 데이터를 정제하기 위해\n",
    "import random # 랜덤 숫자를 생성하기 위해\n",
    "from math import exp, log # 지수함수와 로그함수를 사용하기 위해\n",
    "from datetime import datetime # 시간을 계산하기 위해\n",
    "from operator import itemgetter # 키가 아닌 값으로 max, min 값을 구할 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean(s):\n",
    "    \"\"\"\n",
    "        Returns a cleaned, lowercased string\n",
    "        텍스트 데이터를 정제하고 소문자로 변환해 준다.\n",
    "    \"\"\"\n",
    "    return \" \".join(re.findall(r'\\w+', s, flags = re.UNICODE)).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_tsv(loc_dataset,opts):\n",
    "    \"\"\"\n",
    "    Running through data in an online manner\n",
    "    Parses a tsv file for this competition \n",
    "    and yields label, identifier and features\n",
    "    output:\n",
    "            label: int, The label / target (set to \"1\" if test set)\n",
    "            id: string, the sample identifier\n",
    "            features: list of tuples, \n",
    "                in the form [(hashed_feature_index,feature_value)]\n",
    "\n",
    "    온라인 학습 방법을 통해 데이터를 실행한다.\n",
    "    tsv파일을 통해 레이블, identifier, 피처(특성)를 파싱한다.\n",
    "    결과물:\n",
    "        label : int, 레이블 / 대상 (테스트 집합 인 경우 \"1\"로 설정)\n",
    "        id : 문자열, 샘플 식별자\n",
    "        features : [(hashed_feature_index, feature_value)] \n",
    "                형식의 튜플 목록\n",
    "    \"\"\"\n",
    "    for e, line in enumerate(open(loc_dataset,\"rb\")):\n",
    "        if e > 0:\n",
    "            r = line.decode('utf-8').strip().split(\"\\t\")\n",
    "            id = r[0]\n",
    "\n",
    "            if opts[\"clean\"]:\n",
    "                try:\n",
    "                    r[2] = clean(r[2])\n",
    "                except:\n",
    "                    r[1] = clean(r[1])\n",
    "\n",
    "            # opts[\"D\"] = 2 ** 25 = 33554432\n",
    "            # Vowpal Wabbit의 해싱트릭을 사용한다.\n",
    "            # 해싱트릭은 큰 규모의 feature공간을 \n",
    "            # 고정크기의 표현을 사용해 저장할 수 있게 한다.\n",
    "            if len(r) == 3: # train set\n",
    "                features = [(hash(f)%opts[\"D\"],1) for f in r[2].split()]\n",
    "                label = int(r[1])\n",
    "            else: #test set\n",
    "                features = [(hash(f)%opts[\"D\"],1) for f in r[1].split()]\n",
    "                label = 1\n",
    "\n",
    "            # bigram을 사용하면 해당 피처[i]와 다음피처[i+1]를 함께 해싱한다.\n",
    "            if opts[\"2grams\"]:\n",
    "                for i in range(len(features)-1):\n",
    "                    features.append(\n",
    "                        (hash(str(features[i][0])+str(features[i+1][0]))%opts[\"D\"],1))\n",
    "            yield label, id, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dot_product(features,weights):\n",
    "    \"\"\"\n",
    "    Calculate dot product from features and weights\n",
    "    input:\n",
    "            features: A list of tuples [(feature_index,feature_value)]\n",
    "            weights: the hashing trick weights filter, \n",
    "            note: length is max(feature_index)\n",
    "    output:\n",
    "            dotp: the dot product\n",
    "    피처(특성)과 가중치로부터 내적을 구한다.\n",
    "    \"\"\"\n",
    "    dotp = 0\n",
    "    for f in features:\n",
    "        dotp += weights[f[0]] * f[1]\n",
    "    return dotp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_tron(loc_dataset,opts):\n",
    "    start = datetime.now()\n",
    "    print(\"\\nPass\\t\\tErrors\\t\\tAverage\\t\\tNr. Samples\\tSince Start\")\n",
    "\n",
    "    # 가중치 초기화\n",
    "    if opts[\"random_init\"]:\n",
    "        random.seed(3003)\n",
    "        weights = [random.random()] * opts[\"D\"]\n",
    "    else:\n",
    "        weights = [0.] * opts[\"D\"]\n",
    "\n",
    "    # Running training passes\n",
    "    # 학습 실행\n",
    "    for pass_nr in range(opts[\"n_passes\"]):\n",
    "        error_counter = 0\n",
    "        for e, (label, id, features) in enumerate( \\\n",
    "            get_data_tsv(loc_dataset,opts) ):\n",
    "\n",
    "            # 퍼셉트론은 지도학습 분류기의 일종이다. \n",
    "            # 이전 값에 대한 학습으로 예측을 한다. \n",
    "            # 내적(dotproduct) 값이 임계 값보다 높거나 낮은지에 따라 \n",
    "            # 초과하면 \"1\"을 예측하고 미만이면 \"0\"을 예측한다.\n",
    "            dp = dot_product(features, weights) > 0.5\n",
    "\n",
    "            # 다음 perceptron은 샘플의 레이블을 본다. \n",
    "            # 실제 레이블 데이터에서 위 퍼셉트론으로 구한 dp값을 빼준다.\n",
    "            # 예측이 정확하다면, error 값은 \"0\"이며, 가중치만 남겨 둔다. \n",
    "            # 예측이 틀린 경우 error 값은 \"1\" 또는 \"-1\"이고 다음과 같이 가중치를 업데이트 한다.\n",
    "            # weights[feature_index] += learning_rate * error * feature_value\n",
    "            error = label - dp \n",
    "\n",
    "            # 예측이 틀린 경우 퍼셉트론은 다음과 같이 가중치를 업데이트한다.\n",
    "            if error != 0:\n",
    "                error_counter += 1\n",
    "                # Updating the weights\n",
    "                for index, value in features:\n",
    "                    weights[index] += opts[\"learning_rate\"] * error * log(1.+value)\n",
    "\n",
    "        #Reporting stuff\n",
    "        print(\"%s\\t\\t%s\\t\\t%s\\t\\t%s\\t\\t%s\" % ( \\\n",
    "            pass_nr+1,\n",
    "            error_counter,\n",
    "            round(1 - error_counter /float(e+1),5),\n",
    "            e+1,datetime.now()-start))\n",
    "\n",
    "        #Oh heh, we have overfit :)\n",
    "        if error_counter == 0 or error_counter < opts[\"errors_satisfied\"]:\n",
    "            print(\"%s errors found during training, halting\"%error_counter)\n",
    "            break\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_tron(loc_dataset,weights,opts):\n",
    "    \"\"\"\n",
    "        output:\n",
    "                preds: list, a list with\n",
    "                [id,prediction,dotproduct,0-1normalized dotproduct]\n",
    "    \"\"\"\n",
    "    start = datetime.now()\n",
    "    print(\"\\nTesting online\\nErrors\\t\\tAverage\\t\\tNr. Samples\\tSince Start\")\n",
    "    preds = []\n",
    "    error_counter = 0\n",
    "    for e, (label, id, features) in enumerate( \\\n",
    "        get_data_tsv(loc_dataset,opts) ):\n",
    "\n",
    "        dotp = dot_product(features, weights)\n",
    "        # 내적이 0.5보다 크다면 긍정으로 예측한다.\n",
    "        dp = dotp > 0.5\n",
    "        if dp > 0.5: # we predict positive class\n",
    "            preds.append( [id, 1, dotp ] )\n",
    "        else:\n",
    "            preds.append( [id, 0, dotp ] )\n",
    "\n",
    "        # get_data_tsv에서 테스트 데이터의 레이블을 1로 초기화 해주었음\n",
    "        if label - dp != 0:\n",
    "            error_counter += 1\n",
    "\n",
    "    print(\"%s\\t\\t%s\\t\\t%s\\t\\t%s\" % (\n",
    "        error_counter,\n",
    "        round(1 - error_counter /float(e+1),5),\n",
    "        e+1,\n",
    "        datetime.now()-start))\n",
    "\n",
    "    # normalizing dotproducts between 0 and 1 \n",
    "    # 내적을 구해 0과 1로 일반화 한다.\n",
    "    # TODO: proper probability (bounded sigmoid?), \n",
    "    # online normalization\n",
    "    max_dotp = max(preds,key=itemgetter(2))[2]\n",
    "    min_dotp = min(preds,key=itemgetter(2))[2]\n",
    "    for p in preds:\n",
    "        # appending normalized to predictions\n",
    "        # 정규화 된 값을 마지막에 추가해 준다.\n",
    "        # (피처와 가중치에 대한 내적값 - 최소 내적값) / 최대 내적값 - 최소 내적값\n",
    "        # 이 값이 캐글에서 0.95의 AUC를 얻을 수 있는 값이다.\n",
    "        p.append((p[2]-min_dotp)/float(max_dotp-min_dotp)) \n",
    "\n",
    "    #Reporting stuff\n",
    "    print(\"Done testing in %s\"%str(datetime.now()-start))\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pass\t\tErrors\t\tAverage\t\tNr. Samples\tSince Start\n",
      "1\t\t5681\t\t0.77276\t\t25000\t\t0:00:24.138970\n",
      "2\t\t3120\t\t0.8752\t\t25000\t\t0:00:46.635417\n",
      "3\t\t2217\t\t0.91132\t\t25000\t\t0:01:09.363049\n",
      "4\t\t1693\t\t0.93228\t\t25000\t\t0:01:33.994555\n",
      "5\t\t1256\t\t0.94976\t\t25000\t\t0:01:58.705937\n",
      "6\t\t983\t\t0.96068\t\t25000\t\t0:02:25.440292\n",
      "7\t\t785\t\t0.9686\t\t25000\t\t0:02:47.545708\n",
      "8\t\t657\t\t0.97372\t\t25000\t\t0:03:06.814161\n",
      "9\t\t533\t\t0.97868\t\t25000\t\t0:03:25.614445\n",
      "10\t\t456\t\t0.98176\t\t25000\t\t0:03:43.297138\n",
      "11\t\t402\t\t0.98392\t\t25000\t\t0:04:02.784530\n",
      "12\t\t340\t\t0.9864\t\t25000\t\t0:04:21.439342\n",
      "13\t\t238\t\t0.99048\t\t25000\t\t0:04:39.803828\n",
      "14\t\t210\t\t0.9916\t\t25000\t\t0:04:58.751760\n",
      "15\t\t166\t\t0.99336\t\t25000\t\t0:05:18.760272\n",
      "16\t\t184\t\t0.99264\t\t25000\t\t0:05:36.877885\n",
      "17\t\t164\t\t0.99344\t\t25000\t\t0:05:55.011624\n",
      "18\t\t96\t\t0.99616\t\t25000\t\t0:06:13.289440\n",
      "19\t\t155\t\t0.9938\t\t25000\t\t0:06:32.111081\n",
      "20\t\t154\t\t0.99384\t\t25000\t\t0:06:50.293952\n",
      "21\t\t88\t\t0.99648\t\t25000\t\t0:07:11.175302\n",
      "22\t\t76\t\t0.99696\t\t25000\t\t0:07:37.277693\n",
      "23\t\t74\t\t0.99704\t\t25000\t\t0:07:59.942804\n",
      "24\t\t58\t\t0.99768\t\t25000\t\t0:08:20.947278\n",
      "25\t\t67\t\t0.99732\t\t25000\t\t0:08:42.185962\n",
      "26\t\t53\t\t0.99788\t\t25000\t\t0:09:06.557574\n",
      "27\t\t45\t\t0.9982\t\t25000\t\t0:09:30.480568\n",
      "28\t\t66\t\t0.99736\t\t25000\t\t0:09:52.520910\n",
      "29\t\t55\t\t0.9978\t\t25000\t\t0:10:13.290209\n",
      "30\t\t36\t\t0.99856\t\t25000\t\t0:10:35.132508\n",
      "31\t\t36\t\t0.99856\t\t25000\t\t0:10:58.120495\n",
      "32\t\t20\t\t0.9992\t\t25000\t\t0:11:23.397924\n",
      "33\t\t38\t\t0.99848\t\t25000\t\t0:11:49.320313\n",
      "34\t\t20\t\t0.9992\t\t25000\t\t0:12:11.450667\n",
      "35\t\t15\t\t0.9994\t\t25000\t\t0:12:36.785794\n",
      "36\t\t83\t\t0.99668\t\t25000\t\t0:12:58.120071\n",
      "37\t\t34\t\t0.99864\t\t25000\t\t0:13:18.051144\n",
      "38\t\t4\t\t0.99984\t\t25000\t\t0:13:37.383638\n",
      "39\t\t0\t\t1.0\t\t25000\t\t0:13:57.053914\n",
      "0 errors found during training, halting\n",
      "CPU times: user 12min 35s, sys: 7.84 s, total: 12min 43s\n",
      "Wall time: 13min 57s\n"
     ]
    }
   ],
   "source": [
    "#Setting options\n",
    "opts = {}\n",
    "opts[\"D\"] = 2 ** 25\n",
    "opts[\"learning_rate\"] = 0.1\n",
    "opts[\"n_passes\"] = 80 # Maximum number of passes to run before halting\n",
    "opts[\"errors_satisfied\"] = 0 # Halt when training errors < errors_satisfied\n",
    "opts[\"random_init\"] = False # set random weights, else set all 0\n",
    "opts[\"clean\"] = True # clean the text a little\n",
    "opts[\"2grams\"] = True # add 2grams\n",
    "\n",
    "#training and saving model into weights\n",
    "%time weights = train_tron(\"labeledTrainData.tsv\",opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing online\n",
      "Errors\t\tAverage\t\tNr. Samples\tSince Start\n",
      "12462\t\t0.50152\t\t25000\t\t0:00:19.855956\n",
      "Done testing in 0:00:19.881894\n",
      "CPU times: user 18.5 s, sys: 150 ms, total: 18.7 s\n",
      "Wall time: 19.9 s\n"
     ]
    }
   ],
   "source": [
    "# testing and saving predictions into preds\n",
    "%time preds = test_tron(\"testData.tsv\",weights,opts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['\"12311_10\"', 1, 83.31629110330545, 0.6389283539679332],\n",
       " ['\"8348_2\"', 0, -92.95103691308856, 0.4668831608145605],\n",
       " ['\"5828_4\"', 1, 2.1487562597357783, 0.5597050267234978],\n",
       " ['\"7186_2\"', 0, -6.654212933375497, 0.5511129152290115],\n",
       " ['\"12128_7\"', 1, 31.60751143353347, 0.588458155740479],\n",
       " ['\"2913_8\"', 1, 67.6511648226505, 0.6236384547730207],\n",
       " ['\"4396_1\"', 0, -42.90581047666061, 0.5157296529328205],\n",
       " ['\"395_2\"', 0, -24.67603962793411, 0.5335227657127406],\n",
       " ['\"10616_1\"', 0, -93.15898106725652, 0.4666801975509112],\n",
       " ['\"9074_9\"', 0, -26.131648707110006, 0.5321020228671955]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# writing kaggle submission\n",
    "# 캐글 점수 제출을 위한 서브미션 파일을 작성한다.\n",
    "with open(\"submit_perceptron.csv\",\"wb\") as outfile:\n",
    "    outfile.write('\"id\",\"sentiment\"\\n'.encode('utf-8'))\n",
    "    for p in sorted(preds):\n",
    "        outfile.write(\"{},{}\\n\".format(p[0],p[3]).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"12311_10\"</td>\n",
       "      <td>1</td>\n",
       "      <td>83.316291</td>\n",
       "      <td>0.638928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"8348_2\"</td>\n",
       "      <td>0</td>\n",
       "      <td>-92.951037</td>\n",
       "      <td>0.466883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"5828_4\"</td>\n",
       "      <td>1</td>\n",
       "      <td>2.148756</td>\n",
       "      <td>0.559705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"7186_2\"</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.654213</td>\n",
       "      <td>0.551113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"12128_7\"</td>\n",
       "      <td>1</td>\n",
       "      <td>31.607511</td>\n",
       "      <td>0.588458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0  1          2         3\n",
       "0  \"12311_10\"  1  83.316291  0.638928\n",
       "1    \"8348_2\"  0 -92.951037  0.466883\n",
       "2    \"5828_4\"  1   2.148756  0.559705\n",
       "3    \"7186_2\"  0  -6.654213  0.551113\n",
       "4   \"12128_7\"  1  31.607511  0.588458"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "presult = pd.DataFrame(preds)\n",
    "presult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-76\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    12538\n",
       "0    12462\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sentiment = presult[1].value_counts()\n",
    "print(output_sentiment[0] - output_sentiment[1])\n",
    "output_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1. ,  1.1,\n",
       "        1.2,  1.3,  1.4,  1.5,  1.6,  1.7,  1.8,  1.9,  2. ,  2.1,  2.2,\n",
       "        2.3,  2.4,  2.5,  2.6,  2.7,  2.8,  2.9,  3. ,  3.1,  3.2,  3.3,\n",
       "        3.4,  3.5,  3.6,  3.7,  3.8,  3.9,  4. ,  4.1,  4.2,  4.3,  4.4,\n",
       "        4.5,  4.6,  4.7,  4.8,  4.9,  5. ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
