{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 4 - Understanding and Predicting Property Maintenance Fines\n",
    "\n",
    "This assignment is based on a data challenge from the Michigan Data Science Team ([MDST](http://midas.umich.edu/mdst/)). \n",
    "\n",
    "The Michigan Data Science Team ([MDST](http://midas.umich.edu/mdst/)) and the Michigan Student Symposium for Interdisciplinary Statistical Sciences ([MSSISS](https://sites.lsa.umich.edu/mssiss/)) have partnered with the City of Detroit to help solve one of the most pressing problems facing Detroit - blight. [Blight violations](http://www.detroitmi.gov/How-Do-I/Report/Blight-Complaint-FAQs) are issued by the city to individuals who allow their properties to remain in a deteriorated condition. Every year, the city of Detroit issues millions of dollars in fines to residents and every year, many of these fines remain unpaid. Enforcing unpaid blight fines is a costly and tedious process, so the city wants to know: how can we increase blight ticket compliance?\n",
    "\n",
    "The first step in answering this question is understanding when and why a resident might fail to comply with a blight ticket. This is where predictive modeling comes in. For this assignment, your task is to predict whether a given blight ticket will be paid on time.\n",
    "\n",
    "All data for this assignment has been provided to us through the [Detroit Open Data Portal](https://data.detroitmi.gov/). **Only the data already included in your Coursera directory can be used for training the model for this assignment.** Nonetheless, we encourage you to look into data from other Detroit datasets to help inform feature creation and model selection. We recommend taking a look at the following related datasets:\n",
    "\n",
    "* [Building Permits](https://data.detroitmi.gov/Property-Parcels/Building-Permits/xw2a-a7tf)\n",
    "* [Trades Permits](https://data.detroitmi.gov/Property-Parcels/Trades-Permits/635b-dsgv)\n",
    "* [Improve Detroit: Submitted Issues](https://data.detroitmi.gov/Government/Improve-Detroit-Submitted-Issues/fwz3-w3yn)\n",
    "* [DPD: Citizen Complaints](https://data.detroitmi.gov/Public-Safety/DPD-Citizen-Complaints-2016/kahe-efs3)\n",
    "* [Parcel Map](https://data.detroitmi.gov/Property-Parcels/Parcel-Map/fxkw-udwf)\n",
    "\n",
    "___\n",
    "\n",
    "We provide you with two data files for use in training and validating your models: train.csv and test.csv. Each row in these two files corresponds to a single blight ticket, and includes information about when, why, and to whom each ticket was issued. The target variable is compliance, which is True if the ticket was paid early, on time, or within one month of the hearing data, False if the ticket was paid after the hearing date or not at all, and Null if the violator was found not responsible. Compliance, as well as a handful of other variables that will not be available at test-time, are only included in train.csv.\n",
    "\n",
    "Note: All tickets where the violators were found not responsible are not considered during evaluation. They are included in the training set as an additional source of data for visualization, and to enable unsupervised and semi-supervised approaches. However, they are not included in the test set.\n",
    "\n",
    "<br>\n",
    "\n",
    "**File descriptions** (Use only this data for training your model!)\n",
    "\n",
    "    train.csv - the training set (all tickets issued 2004-2011)\n",
    "    test.csv - the test set (all tickets issued 2012-2016)\n",
    "    addresses.csv & latlons.csv - mapping from ticket id to addresses, and from addresses to lat/lon coordinates. \n",
    "     Note: misspelled addresses may be incorrectly geolocated.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Data fields**\n",
    "\n",
    "train.csv & test.csv\n",
    "\n",
    "    ticket_id - unique identifier for tickets\n",
    "    agency_name - Agency that issued the ticket\n",
    "    inspector_name - Name of inspector that issued the ticket\n",
    "    violator_name - Name of the person/organization that the ticket was issued to\n",
    "    violation_street_number, violation_street_name, violation_zip_code - Address where the violation occurred\n",
    "    mailing_address_str_number, mailing_address_str_name, city, state, zip_code, non_us_str_code, country - Mailing address of the violator\n",
    "    ticket_issued_date - Date and time the ticket was issued\n",
    "    hearing_date - Date and time the violator's hearing was scheduled\n",
    "    violation_code, violation_description - Type of violation\n",
    "    disposition - Judgment and judgement type\n",
    "    fine_amount - Violation fine amount, excluding fees\n",
    "    admin_fee - $20 fee assigned to responsible judgments\n",
    "state_fee - $10 fee assigned to responsible judgments\n",
    "    late_fee - 10% fee assigned to responsible judgments\n",
    "    discount_amount - discount applied, if any\n",
    "    clean_up_cost - DPW clean-up or graffiti removal cost\n",
    "    judgment_amount - Sum of all fines and fees\n",
    "    grafitti_status - Flag for graffiti violations\n",
    "    \n",
    "train.csv only\n",
    "\n",
    "    payment_amount - Amount paid, if any\n",
    "    payment_date - Date payment was made, if it was received\n",
    "    payment_status - Current payment status as of Feb 1 2017\n",
    "    balance_due - Fines and fees still owed\n",
    "    collection_status - Flag for payments in collections\n",
    "    compliance [target variable for prediction] \n",
    "     Null = Not responsible\n",
    "     0 = Responsible, non-compliant\n",
    "     1 = Responsible, compliant\n",
    "    compliance_detail - More information on why each ticket was marked compliant or non-compliant\n",
    "\n",
    "\n",
    "___\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "Your predictions will be given as the probability that the corresponding blight ticket will be paid on time.\n",
    "\n",
    "The evaluation metric for this assignment is the Area Under the ROC Curve (AUC). \n",
    "\n",
    "Your grade will be based on the AUC score computed for your classifier. A model which with an AUROC of 0.7 passes this assignment, over 0.75 will recieve full points.\n",
    "___\n",
    "\n",
    "For this assignment, create a function that trains a model to predict blight ticket compliance in Detroit using `train.csv`. Using this model, return a series of length 61001 with the data being the probability that each corresponding ticket from `test.csv` will be paid, and the index being the ticket_id.\n",
    "\n",
    "Example:\n",
    "\n",
    "    ticket_id\n",
    "       284932    0.531842\n",
    "       285362    0.401958\n",
    "       285361    0.105928\n",
    "       285338    0.018572\n",
    "                 ...\n",
    "       376499    0.208567\n",
    "       376500    0.818759\n",
    "       369851    0.018528\n",
    "       Name: compliance, dtype: float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set: (250306, 34) , test set: (61001, 27) , latlons: (121769, 3) , address: (311307, 2)\n"
     ]
    }
   ],
   "source": [
    "# Read files.\n",
    "# The training data is indeed not encoded as UTF-8 so note the encoding parameter.\n",
    "train = pd.read_csv('train.csv', encoding='cp1252')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "latlons = pd.read_csv('latlons.csv')\n",
    "address = pd.read_csv('addresses.csv')\n",
    "\n",
    "print('training set:', train.shape,',', 'test set:', test.shape,',', 'latlons:',latlons.shape,',', 'address:',address.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data Leakage\n",
    "\n",
    "We need to remove all data just prior to the event of interest, in our case, 'payment_amount','balance_due', 'payment_due', 'payment_status', etc. These columns will cause our model too optimistic, which leads to a overfitting problem since this kind of information will not be given with unseen data in practice. Also without knowing the result of the status of tickets will be paid on time, there is no way we can know them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['payment_amount', 'balance_due', 'payment_date', 'payment_status', 'collection_status', 'compliance_detail']\n"
     ]
    }
   ],
   "source": [
    "# In order to avoid either data leakage or too many missing values, remove some columns does not exist \n",
    "# in test dataset except for the target variable 'compliance'.\n",
    "elimi_col = [col for col in train.columns if(col not in test.columns)][:-1]\n",
    "print(elimi_col)\n",
    "\n",
    "train = train.drop(elimi_col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22056</td>\n",
       "      <td>2900 tyler, Detroit MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27586</td>\n",
       "      <td>4311 central, Detroit MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22062</td>\n",
       "      <td>1449 longfellow, Detroit MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22084</td>\n",
       "      <td>1441 longfellow, Detroit MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22093</td>\n",
       "      <td>2449 churchill, Detroit MI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ticket_id                      address\n",
       "0      22056       2900 tyler, Detroit MI\n",
       "1      27586     4311 central, Detroit MI\n",
       "2      22062  1449 longfellow, Detroit MI\n",
       "3      22084  1441 longfellow, Detroit MI\n",
       "4      22093   2449 churchill, Detroit MI"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4300 rosa parks blvd, Detroit MI 48208</td>\n",
       "      <td>42.346169</td>\n",
       "      <td>-83.079962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14512 sussex, Detroit MI</td>\n",
       "      <td>42.394657</td>\n",
       "      <td>-83.194265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3456 garland, Detroit MI</td>\n",
       "      <td>42.373779</td>\n",
       "      <td>-82.986228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5787 wayburn, Detroit MI</td>\n",
       "      <td>42.403342</td>\n",
       "      <td>-82.957805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5766 haverhill, Detroit MI</td>\n",
       "      <td>42.407255</td>\n",
       "      <td>-82.946295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  address        lat        lon\n",
       "0  4300 rosa parks blvd, Detroit MI 48208  42.346169 -83.079962\n",
       "1                14512 sussex, Detroit MI  42.394657 -83.194265\n",
       "2                3456 garland, Detroit MI  42.373779 -82.986228\n",
       "3                5787 wayburn, Detroit MI  42.403342 -82.957805\n",
       "4              5766 haverhill, Detroit MI  42.407255 -82.946295"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latlons.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By just looking at the first sight, it appears that we can merge address and latlons dataframes by the common column \"address\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>address</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22056</td>\n",
       "      <td>2900 tyler, Detroit MI</td>\n",
       "      <td>42.390729</td>\n",
       "      <td>-83.124268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77242</td>\n",
       "      <td>2900 tyler, Detroit MI</td>\n",
       "      <td>42.390729</td>\n",
       "      <td>-83.124268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77243</td>\n",
       "      <td>2900 tyler, Detroit MI</td>\n",
       "      <td>42.390729</td>\n",
       "      <td>-83.124268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103945</td>\n",
       "      <td>2900 tyler, Detroit MI</td>\n",
       "      <td>42.390729</td>\n",
       "      <td>-83.124268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>138219</td>\n",
       "      <td>2900 tyler, Detroit MI</td>\n",
       "      <td>42.390729</td>\n",
       "      <td>-83.124268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ticket_id                 address        lat        lon\n",
       "0      22056  2900 tyler, Detroit MI  42.390729 -83.124268\n",
       "1      77242  2900 tyler, Detroit MI  42.390729 -83.124268\n",
       "2      77243  2900 tyler, Detroit MI  42.390729 -83.124268\n",
       "3     103945  2900 tyler, Detroit MI  42.390729 -83.124268\n",
       "4     138219  2900 tyler, Detroit MI  42.390729 -83.124268"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loca = address.merge(latlons, how = 'outer', left_on = 'address', right_on = 'address')\n",
    "loca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a same property can have multiple ticket_id (tickets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>agency_name</th>\n",
       "      <th>inspector_name</th>\n",
       "      <th>violator_name</th>\n",
       "      <th>violation_street_number</th>\n",
       "      <th>violation_street_name</th>\n",
       "      <th>violation_zip_code</th>\n",
       "      <th>mailing_address_str_number</th>\n",
       "      <th>mailing_address_str_name</th>\n",
       "      <th>city</th>\n",
       "      <th>...</th>\n",
       "      <th>state_fee</th>\n",
       "      <th>late_fee</th>\n",
       "      <th>discount_amount</th>\n",
       "      <th>clean_up_cost</th>\n",
       "      <th>judgment_amount</th>\n",
       "      <th>grafitti_status</th>\n",
       "      <th>compliance</th>\n",
       "      <th>address</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22056</td>\n",
       "      <td>Buildings, Safety Engineering &amp; Env Department</td>\n",
       "      <td>Sims, Martinzie</td>\n",
       "      <td>INVESTMENT INC., MIDWEST MORTGAGE</td>\n",
       "      <td>2900.0</td>\n",
       "      <td>TYLER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>S. WICKER</td>\n",
       "      <td>CHICAGO</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2900 tyler, Detroit MI</td>\n",
       "      <td>42.390729</td>\n",
       "      <td>-83.124268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27586</td>\n",
       "      <td>Buildings, Safety Engineering &amp; Env Department</td>\n",
       "      <td>Williams, Darrin</td>\n",
       "      <td>Michigan, Covenant House</td>\n",
       "      <td>4311.0</td>\n",
       "      <td>CENTRAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2959.0</td>\n",
       "      <td>Martin Luther King</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>855.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4311 central, Detroit MI</td>\n",
       "      <td>42.326937</td>\n",
       "      <td>-83.135118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22062</td>\n",
       "      <td>Buildings, Safety Engineering &amp; Env Department</td>\n",
       "      <td>Sims, Martinzie</td>\n",
       "      <td>SANDERS, DERRON</td>\n",
       "      <td>1449.0</td>\n",
       "      <td>LONGFELLOW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23658.0</td>\n",
       "      <td>P.O. BOX</td>\n",
       "      <td>DETROIT</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1449 longfellow, Detroit MI</td>\n",
       "      <td>42.380516</td>\n",
       "      <td>-83.096069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22084</td>\n",
       "      <td>Buildings, Safety Engineering &amp; Env Department</td>\n",
       "      <td>Sims, Martinzie</td>\n",
       "      <td>MOROSI, MIKE</td>\n",
       "      <td>1441.0</td>\n",
       "      <td>LONGFELLOW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>ST. CLAIR</td>\n",
       "      <td>DETROIT</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1441 longfellow, Detroit MI</td>\n",
       "      <td>42.380570</td>\n",
       "      <td>-83.095919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22093</td>\n",
       "      <td>Buildings, Safety Engineering &amp; Env Department</td>\n",
       "      <td>Sims, Martinzie</td>\n",
       "      <td>NATHANIEL, NEAL</td>\n",
       "      <td>2449.0</td>\n",
       "      <td>CHURCHILL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7449.0</td>\n",
       "      <td>CHURCHILL</td>\n",
       "      <td>DETROIT</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2449 churchill, Detroit MI</td>\n",
       "      <td>42.145257</td>\n",
       "      <td>-83.208233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ticket_id                                     agency_name  \\\n",
       "0      22056  Buildings, Safety Engineering & Env Department   \n",
       "1      27586  Buildings, Safety Engineering & Env Department   \n",
       "2      22062  Buildings, Safety Engineering & Env Department   \n",
       "3      22084  Buildings, Safety Engineering & Env Department   \n",
       "4      22093  Buildings, Safety Engineering & Env Department   \n",
       "\n",
       "     inspector_name                      violator_name  \\\n",
       "0   Sims, Martinzie  INVESTMENT INC., MIDWEST MORTGAGE   \n",
       "1  Williams, Darrin           Michigan, Covenant House   \n",
       "2   Sims, Martinzie                    SANDERS, DERRON   \n",
       "3   Sims, Martinzie                       MOROSI, MIKE   \n",
       "4   Sims, Martinzie                    NATHANIEL, NEAL   \n",
       "\n",
       "   violation_street_number violation_street_name  violation_zip_code  \\\n",
       "0                   2900.0                 TYLER                 NaN   \n",
       "1                   4311.0               CENTRAL                 NaN   \n",
       "2                   1449.0            LONGFELLOW                 NaN   \n",
       "3                   1441.0            LONGFELLOW                 NaN   \n",
       "4                   2449.0             CHURCHILL                 NaN   \n",
       "\n",
       "   mailing_address_str_number mailing_address_str_name     city    ...      \\\n",
       "0                         3.0                S. WICKER  CHICAGO    ...       \n",
       "1                      2959.0       Martin Luther King  Detroit    ...       \n",
       "2                     23658.0                 P.O. BOX  DETROIT    ...       \n",
       "3                         5.0                ST. CLAIR  DETROIT    ...       \n",
       "4                      7449.0                CHURCHILL  DETROIT    ...       \n",
       "\n",
       "  state_fee late_fee discount_amount clean_up_cost judgment_amount  \\\n",
       "0      10.0     25.0             0.0           0.0           305.0   \n",
       "1      10.0     75.0             0.0           0.0           855.0   \n",
       "2       0.0      0.0             0.0           0.0             0.0   \n",
       "3       0.0      0.0             0.0           0.0             0.0   \n",
       "4       0.0      0.0             0.0           0.0             0.0   \n",
       "\n",
       "  grafitti_status compliance                      address        lat  \\\n",
       "0             NaN        0.0       2900 tyler, Detroit MI  42.390729   \n",
       "1             NaN        1.0     4311 central, Detroit MI  42.326937   \n",
       "2             NaN        NaN  1449 longfellow, Detroit MI  42.380516   \n",
       "3             NaN        NaN  1441 longfellow, Detroit MI  42.380570   \n",
       "4             NaN        NaN   2449 churchill, Detroit MI  42.145257   \n",
       "\n",
       "         lon  \n",
       "0 -83.124268  \n",
       "1 -83.135118  \n",
       "2 -83.096069  \n",
       "3 -83.095919  \n",
       "4 -83.208233  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.merge(loca, how = 'inner', left_on = 'ticket_id', right_on = 'ticket_id')\n",
    "test = test.merge(loca, how = 'inner',left_on = 'ticket_id', right_on = 'ticket_id')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set: (250306, 31)\n",
      "test set: (61001, 30)\n"
     ]
    }
   ],
   "source": [
    "print('training set:', train.shape)\n",
    "print(\"test set:\",test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing & Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "violator_name                     34\n",
       "violation_zip_code            250306\n",
       "mailing_address_str_number      3602\n",
       "mailing_address_str_name           4\n",
       "state                             93\n",
       "zip_code                           1\n",
       "non_us_str_code               250303\n",
       "hearing_date                   12491\n",
       "fine_amount                        1\n",
       "grafitti_status               250305\n",
       "compliance                     90426\n",
       "lat                                3\n",
       "lon                                3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()[train.isnull().sum() >= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "violator_name                    28\n",
       "violation_zip_code            36977\n",
       "mailing_address_str_number     1014\n",
       "mailing_address_str_name          3\n",
       "state                           331\n",
       "zip_code                          3\n",
       "non_us_str_code               61001\n",
       "hearing_date                   2197\n",
       "fine_amount                       0\n",
       "grafitti_status               58780\n",
       "lat                               5\n",
       "lon                               5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()[train.isnull().sum() >= 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the above, three columns 'violation_zipcode','non_us_str_code','grafitti_status' have too many missing values. Therefore, remove these columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.10 Violation Zip Code, Non Us Str Code, Grafitti status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.drop(['violation_zip_code','non_us_str_code','grafitti_status'], axis=1, inplace=True)\n",
    "test.drop(['violation_zip_code','non_us_str_code','grafitti_status'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.11 Number of NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For the convenience for counting the number of nulls in each row, create the new column 'num_null'\n",
    "\n",
    "train['num_null'] = train.isnull().sum(axis=1)\n",
    "test['num_null'] = test.isnull().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.12 Lat/Lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in training lat and lon: 2 Missing values in test lat and lon: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>agency_name</th>\n",
       "      <th>inspector_name</th>\n",
       "      <th>violator_name</th>\n",
       "      <th>violation_street_number</th>\n",
       "      <th>violation_street_name</th>\n",
       "      <th>mailing_address_str_number</th>\n",
       "      <th>mailing_address_str_name</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>...</th>\n",
       "      <th>state_fee</th>\n",
       "      <th>late_fee</th>\n",
       "      <th>discount_amount</th>\n",
       "      <th>clean_up_cost</th>\n",
       "      <th>judgment_amount</th>\n",
       "      <th>compliance</th>\n",
       "      <th>address</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>num_null</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>191722</th>\n",
       "      <td>223598</td>\n",
       "      <td>Buildings, Safety Engineering &amp; Env Department</td>\n",
       "      <td>O'Neal, Claude</td>\n",
       "      <td>HJADJANTONI, MICHAEL</td>\n",
       "      <td>445.0</td>\n",
       "      <td>FORDYCE</td>\n",
       "      <td>437.0</td>\n",
       "      <td>FOREST</td>\n",
       "      <td>DETROIT</td>\n",
       "      <td>MI</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>445 fordyce, Detroit MI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245981</th>\n",
       "      <td>280256</td>\n",
       "      <td>Department of Public Works</td>\n",
       "      <td>McCants, Angela</td>\n",
       "      <td>HOLDINGS LLC, FORDYCE</td>\n",
       "      <td>8300.0</td>\n",
       "      <td>FORDYCE</td>\n",
       "      <td>151.0</td>\n",
       "      <td>POTOMIC</td>\n",
       "      <td>ROCHESTER HILLS</td>\n",
       "      <td>MI</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8300 fordyce, Detroit MI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ticket_id                                     agency_name  \\\n",
       "191722     223598  Buildings, Safety Engineering & Env Department   \n",
       "245981     280256                      Department of Public Works   \n",
       "\n",
       "         inspector_name          violator_name  violation_street_number  \\\n",
       "191722   O'Neal, Claude   HJADJANTONI, MICHAEL                    445.0   \n",
       "245981  McCants, Angela  HOLDINGS LLC, FORDYCE                   8300.0   \n",
       "\n",
       "       violation_street_name  mailing_address_str_number  \\\n",
       "191722               FORDYCE                       437.0   \n",
       "245981               FORDYCE                       151.0   \n",
       "\n",
       "       mailing_address_str_name             city state    ...    state_fee  \\\n",
       "191722                   FOREST          DETROIT    MI    ...         10.0   \n",
       "245981                  POTOMIC  ROCHESTER HILLS    MI    ...          0.0   \n",
       "\n",
       "       late_fee discount_amount clean_up_cost judgment_amount compliance  \\\n",
       "191722     25.0             0.0           0.0           305.0        0.0   \n",
       "245981      0.0             0.0           0.0             0.0        NaN   \n",
       "\n",
       "                         address  lat  lon  num_null  \n",
       "191722   445 fordyce, Detroit MI  NaN  NaN         2  \n",
       "245981  8300 fordyce, Detroit MI  NaN  NaN         3  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training set lat,lon:\n",
    "# Since there are some missing values found in both training and test set, \n",
    "# we need to manually find the lat and lon coordinates from google map by searching the given addresses\n",
    "\n",
    "# 20424 bramford, Detroit MI, (42.446558,-83.022996)\n",
    "train.iloc[65578,-3] = 42.446558\n",
    "train.iloc[65578,-2] = -83.022996\n",
    "\n",
    "# Fail to find the lat and lon coordinates for the ticket_id 223598 and 280256 from google map \n",
    "# since the rest of two other places are showing too wide area (google map cannot pinpoint where it is).\n",
    "\n",
    "# Test Set lat,lon:\n",
    "\n",
    "# 20424 bramford, Detroit MI, (42.446558,-83.022996)\n",
    "test.iloc[20459,-3] = 42.446558\n",
    "test.iloc[20459,-2] = -83.022996\n",
    "\n",
    "# 8325 joy rd, Detroit MI 48204, (42.359024, -83.150799)\n",
    "test.iloc[28350,-3] = 42.359024 \n",
    "test.iloc[28350,-2] = -83.150799\n",
    "\n",
    "# 1201 elijah mccoy dr, Detroit MI 48208, (42.358760, -83.080382)\n",
    "test.iloc[28416,-3] = 42.358760\n",
    "test.iloc[28416,-2] = -83.080382\n",
    "\n",
    "# 12038 prairie, Detroit MI 482O4, (42.376943, -83.143206)\n",
    "test.iloc[31925,-3] = 42.376943\n",
    "test.iloc[31925,-2] = -83.143206\n",
    "\n",
    "# 6200 16th st, Detroit MI 48208 (42.360104, -83.095872)\n",
    "test.iloc[55400,-3] = 42.360104\n",
    "test.iloc[55400,-2] = -83.095872\n",
    "\n",
    "# Check how many null values are in train and test\n",
    "print('Missing values in training lat and lon:',len(train[train.lon.isnull()]), 'Missing values in test lat and lon:',len(test[test.lon.isnull()]))\n",
    "\n",
    "# Check the table.\n",
    "train[train.lon.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# As you can see, there are still two missing values which cannot be found in google map; therefore, needed to be filled with\n",
    "# 0.0 lat and lon (or some distinguishable number from other lat, lon but I decided to choose 0.0). \n",
    "# Except for these two values, all the values do not have any problem so leave the rows instead of dropping the rows.\n",
    "train.lat[train.lat.isnull()] = 0.0\n",
    "train.lon[train.lon.isnull()] = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we converted most of violation addresses to lat and lon coordinate, 'violation_street_number','violation_street_name','address' variables are no longer needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.13 Violation Street Number , Violation Street Name, Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.drop(['violation_street_number','violation_street_name','address'], axis = 1, inplace = True)\n",
    "test.drop(['violation_street_number','violation_street_name','address'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.14 Country / State / City / New Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mailing_address_str_number</th>\n",
       "      <th>mailing_address_str_name</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>country</th>\n",
       "      <th>ticket_issued_date</th>\n",
       "      <th>hearing_date</th>\n",
       "      <th>violation_code</th>\n",
       "      <th>violation_description</th>\n",
       "      <th>disposition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>183911</th>\n",
       "      <td>NaN</td>\n",
       "      <td>P. O. BOX 26334</td>\n",
       "      <td>MANAMA HAHRAIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>2009-04-22 10:45:00</td>\n",
       "      <td>2009-05-28 10:30:00</td>\n",
       "      <td>22-2-88</td>\n",
       "      <td>Failure of owner to keep property, its sidewal...</td>\n",
       "      <td>Responsible by Default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186126</th>\n",
       "      <td>3212.0</td>\n",
       "      <td>MCCARRON CRES</td>\n",
       "      <td>MISS, ONTARIO, CANADA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L5N 3H5</td>\n",
       "      <td>USA</td>\n",
       "      <td>2009-05-08 10:40:00</td>\n",
       "      <td>2009-06-18 13:30:00</td>\n",
       "      <td>22-2-88</td>\n",
       "      <td>Failure of owner to keep property, its sidewal...</td>\n",
       "      <td>Responsible by Admission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188915</th>\n",
       "      <td>NaN</td>\n",
       "      <td>FOXWOOD CHALKY ROAD</td>\n",
       "      <td>STOCKBURG KENT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>2009-06-04 13:30:00</td>\n",
       "      <td>2009-10-29 10:30:00</td>\n",
       "      <td>9-1-104</td>\n",
       "      <td>Excessive weeds or plant growth one- or two-fa...</td>\n",
       "      <td>Responsible by Default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190375</th>\n",
       "      <td>1.0</td>\n",
       "      <td>PARTIGLIANO</td>\n",
       "      <td>LUCCA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55067</td>\n",
       "      <td>USA</td>\n",
       "      <td>2009-06-23 13:30:00</td>\n",
       "      <td>2009-08-05 13:30:00</td>\n",
       "      <td>9-1-105</td>\n",
       "      <td>Rodent harborage one-or two-family dwelling or...</td>\n",
       "      <td>Responsible by Admission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191245</th>\n",
       "      <td>29.0</td>\n",
       "      <td>CHERRY  TREE  CT</td>\n",
       "      <td>CHARLESTON LONDON, ENGLAND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SE 770X</td>\n",
       "      <td>USA</td>\n",
       "      <td>2009-07-07 09:50:00</td>\n",
       "      <td>2009-08-18 13:30:00</td>\n",
       "      <td>9-1-104</td>\n",
       "      <td>Excessive weeds or plant growth one- or two-fa...</td>\n",
       "      <td>Responsible by Admission</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mailing_address_str_number mailing_address_str_name  \\\n",
       "183911                         NaN          P. O. BOX 26334   \n",
       "186126                      3212.0            MCCARRON CRES   \n",
       "188915                         NaN      FOXWOOD CHALKY ROAD   \n",
       "190375                         1.0              PARTIGLIANO   \n",
       "191245                        29.0         CHERRY  TREE  CT   \n",
       "\n",
       "                              city state zip_code country  \\\n",
       "183911              MANAMA HAHRAIN   NaN        0     USA   \n",
       "186126       MISS, ONTARIO, CANADA   NaN  L5N 3H5     USA   \n",
       "188915              STOCKBURG KENT   NaN        0     USA   \n",
       "190375                       LUCCA   NaN    55067     USA   \n",
       "191245  CHARLESTON LONDON, ENGLAND   NaN  SE 770X     USA   \n",
       "\n",
       "         ticket_issued_date         hearing_date violation_code  \\\n",
       "183911  2009-04-22 10:45:00  2009-05-28 10:30:00        22-2-88   \n",
       "186126  2009-05-08 10:40:00  2009-06-18 13:30:00        22-2-88   \n",
       "188915  2009-06-04 13:30:00  2009-10-29 10:30:00        9-1-104   \n",
       "190375  2009-06-23 13:30:00  2009-08-05 13:30:00        9-1-105   \n",
       "191245  2009-07-07 09:50:00  2009-08-18 13:30:00        9-1-104   \n",
       "\n",
       "                                    violation_description  \\\n",
       "183911  Failure of owner to keep property, its sidewal...   \n",
       "186126  Failure of owner to keep property, its sidewal...   \n",
       "188915  Excessive weeds or plant growth one- or two-fa...   \n",
       "190375  Rodent harborage one-or two-family dwelling or...   \n",
       "191245  Excessive weeds or plant growth one- or two-fa...   \n",
       "\n",
       "                     disposition  \n",
       "183911    Responsible by Default  \n",
       "186126  Responsible by Admission  \n",
       "188915    Responsible by Default  \n",
       "190375  Responsible by Admission  \n",
       "191245  Responsible by Admission  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As you can see the country and city column, there are some discrepancies between city and country. \n",
    "# ex) on ticket number 218570, city is Ontario, Canada but the country denotes USA.\n",
    "train[train.state.isnull()].iloc[:,4:15].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mailing_address_str_name</th>\n",
       "      <th>city</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>183911</th>\n",
       "      <td>P. O. BOX 26334</td>\n",
       "      <td>MANAMA HAHRAIN</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186126</th>\n",
       "      <td>MCCARRON CRES</td>\n",
       "      <td>MISS, ONTARIO, CANADA</td>\n",
       "      <td>L5N 3H5</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188915</th>\n",
       "      <td>FOXWOOD CHALKY ROAD</td>\n",
       "      <td>STOCKBURG KENT</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190375</th>\n",
       "      <td>PARTIGLIANO</td>\n",
       "      <td>LUCCA</td>\n",
       "      <td>55067</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191245</th>\n",
       "      <td>CHERRY  TREE  CT</td>\n",
       "      <td>CHARLESTON LONDON, ENGLAND</td>\n",
       "      <td>SE 770X</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193547</th>\n",
       "      <td>THORN  STREET</td>\n",
       "      <td>Woodville, United Kingdom</td>\n",
       "      <td>Deli-7DN</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194701</th>\n",
       "      <td>TOOLEY</td>\n",
       "      <td>LONDON SE12ET</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203041</th>\n",
       "      <td>BRIARWOOD AVE</td>\n",
       "      <td>TORONTO  ONTARIO, CANADA</td>\n",
       "      <td>M9W6C9</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203042</th>\n",
       "      <td>BRIARWOOD AVE</td>\n",
       "      <td>TORONTO  ONTARIO, CANADA</td>\n",
       "      <td>M9W6C9</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203043</th>\n",
       "      <td>BRIARWOOD AVE</td>\n",
       "      <td>TORONTO  ONTARIO, CANADA</td>\n",
       "      <td>M9W6C9</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216567</th>\n",
       "      <td>TAIMOR</td>\n",
       "      <td>ST. FATIMA SQ. HELIOPOLIS, CAIRO, EGYPT</td>\n",
       "      <td>11361</td>\n",
       "      <td>Egyp</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216568</th>\n",
       "      <td>TAIMOR ST</td>\n",
       "      <td>ST. FATIMA SQ. HELIOPOLIS, CAIRO, EGYPT</td>\n",
       "      <td>11361</td>\n",
       "      <td>Egyp</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216927</th>\n",
       "      <td>ELMONT  DRIVE</td>\n",
       "      <td>CALGARY, ALBERTA, CANADA</td>\n",
       "      <td>T3H-4X8</td>\n",
       "      <td>Cana</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217529</th>\n",
       "      <td>ELMONT DR.</td>\n",
       "      <td>CALGARY, ALBERTA, CANADA</td>\n",
       "      <td>T3H-4X8</td>\n",
       "      <td>Cana</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220371</th>\n",
       "      <td>ROBINA TOWN CENTER DR</td>\n",
       "      <td>ROBINA  QLD</td>\n",
       "      <td>4226</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220407</th>\n",
       "      <td>LAUREN MEWS HAYLING ISLAND</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220533</th>\n",
       "      <td>MILLER  BALLARAT</td>\n",
       "      <td>VICTORIA</td>\n",
       "      <td>3350</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223243</th>\n",
       "      <td>FOXWOOD, CHALKY RD.</td>\n",
       "      <td>STOCKBURY,  KENT</td>\n",
       "      <td>ME9,7QR UK</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223334</th>\n",
       "      <td>RUE DES LILAS</td>\n",
       "      <td>ALFORTEVILLE, FRANCE</td>\n",
       "      <td>94140</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223335</th>\n",
       "      <td>RUE DES LILAS</td>\n",
       "      <td>ALFORTEVILLE, FRANCE</td>\n",
       "      <td>94140</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224720</th>\n",
       "      <td>ELMONT DR.</td>\n",
       "      <td>CALVARY ALBERTA</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225113</th>\n",
       "      <td>BLK 213 BATILE BATOK, STE 012</td>\n",
       "      <td>SINGAPORE</td>\n",
       "      <td>650213</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225794</th>\n",
       "      <td>P.O. BOX</td>\n",
       "      <td>BET ZAIT, ISRAEL</td>\n",
       "      <td>90815</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225795</th>\n",
       "      <td>P.O. BOX</td>\n",
       "      <td>BET ZAIT, ISRAEL</td>\n",
       "      <td>90815</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225796</th>\n",
       "      <td>P.O. BOX</td>\n",
       "      <td>BET ZAIT, ISRAEL</td>\n",
       "      <td>90815</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227074</th>\n",
       "      <td>GLENNIE PLACE</td>\n",
       "      <td>QUEANBEYAN, NSW</td>\n",
       "      <td>2620</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227161</th>\n",
       "      <td>PINE LODGE, LOWOOD, ARMATHWAIT</td>\n",
       "      <td>CARLISLE CUMBRIAN</td>\n",
       "      <td>49</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227736</th>\n",
       "      <td>CLUNE TERRACE</td>\n",
       "      <td>NEWTONMORE</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227737</th>\n",
       "      <td>CLUNE TERRACE</td>\n",
       "      <td>NEWTONMORE</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227964</th>\n",
       "      <td>ELMONT, DR.</td>\n",
       "      <td>CALGARY ALBERTA</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244324</th>\n",
       "      <td>ALBANY  HWY</td>\n",
       "      <td>MT. BARKER</td>\n",
       "      <td>6324</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244407</th>\n",
       "      <td>BUKIT BATOK CRESENT</td>\n",
       "      <td>WCEGA TOWER 03-74</td>\n",
       "      <td>658065</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244547</th>\n",
       "      <td>CORNER OF GRADUATE CRESCENT</td>\n",
       "      <td>BELIZE CITY</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244660</th>\n",
       "      <td>180,ON NUT S0135,SUKNHUMVIT</td>\n",
       "      <td>BANGKOK</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244661</th>\n",
       "      <td>180,ON NUT SOI  35  SUKHUMVIT</td>\n",
       "      <td>BONGKOK</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244799</th>\n",
       "      <td>MASLISANSKY ST</td>\n",
       "      <td>RAMOT JERUSALEM</td>\n",
       "      <td>97225</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244856</th>\n",
       "      <td>NAVAHO DR.</td>\n",
       "      <td>TORONTO</td>\n",
       "      <td>222</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244894</th>\n",
       "      <td>WHITEGLEN CRES</td>\n",
       "      <td>N. E. CALGARY</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244895</th>\n",
       "      <td>NAVAHO DR.</td>\n",
       "      <td>TORONTO</td>\n",
       "      <td>22</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245023</th>\n",
       "      <td>TURNER CLOSE CREWE</td>\n",
       "      <td>CHESHIRE</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245024</th>\n",
       "      <td>TURNER CREWE</td>\n",
       "      <td>CHESHIRE</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245302</th>\n",
       "      <td>BERKLEY CRES NW</td>\n",
       "      <td>CALGARY,ALBERTA</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245316</th>\n",
       "      <td>ELMONT DR. SW</td>\n",
       "      <td>CALGARY</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245957</th>\n",
       "      <td>MAYNARD RD</td>\n",
       "      <td>WALTHAM</td>\n",
       "      <td>179</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245958</th>\n",
       "      <td>MAYNARD RD</td>\n",
       "      <td>WALTHAM</td>\n",
       "      <td>179</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246218</th>\n",
       "      <td>ABBOTS GARDENS</td>\n",
       "      <td>LODON ,N2OJE,UK</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247060</th>\n",
       "      <td>HAGALIL</td>\n",
       "      <td>GANIC TIKVA ,ISRAEL</td>\n",
       "      <td>55900</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247422</th>\n",
       "      <td>DE 'I INFANTE</td>\n",
       "      <td>WATERLOO</td>\n",
       "      <td>1401</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247515</th>\n",
       "      <td>RADFORD</td>\n",
       "      <td>ONTARIO</td>\n",
       "      <td>342</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247907</th>\n",
       "      <td>KNIGHT CLOSE</td>\n",
       "      <td>NEW SOUTH WALES</td>\n",
       "      <td>2448</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248034</th>\n",
       "      <td>SASAMEMINAMI</td>\n",
       "      <td>TADA CITY</td>\n",
       "      <td>3350035</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248257</th>\n",
       "      <td>HORSESHOE WAY  UNIT 133</td>\n",
       "      <td>RICHMOND BC</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248379</th>\n",
       "      <td>BUKIT BATOK CRESCENT</td>\n",
       "      <td>SINGAPORE</td>\n",
       "      <td>658065</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248967</th>\n",
       "      <td>TYNE ST</td>\n",
       "      <td>BOX HILL NORTH, VICTORIA AUSTRALIA</td>\n",
       "      <td>3129</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248968</th>\n",
       "      <td>TYNE ST</td>\n",
       "      <td>BOX HILL NORTH, VICTORIA AUSTRALIA</td>\n",
       "      <td>3129</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249009</th>\n",
       "      <td>MANOR FARM,SOUTH NEWTON</td>\n",
       "      <td>SALISBURY,WILT,SP2, OQD,</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249505</th>\n",
       "      <td>TENTH LIVERPOOL ST.</td>\n",
       "      <td>ROSE BAY</td>\n",
       "      <td>2029</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249762</th>\n",
       "      <td>LAUNCESTON PL</td>\n",
       "      <td>UNITED KINGDOM</td>\n",
       "      <td>157</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249874</th>\n",
       "      <td>CLADE ST.</td>\n",
       "      <td>BEULAH SOUTH</td>\n",
       "      <td>5067</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250070</th>\n",
       "      <td>CRESCENT WCEGA TOWER</td>\n",
       "      <td>BUKIT BATOK</td>\n",
       "      <td>658065</td>\n",
       "      <td>USA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              mailing_address_str_name  \\\n",
       "183911                 P. O. BOX 26334   \n",
       "186126                   MCCARRON CRES   \n",
       "188915             FOXWOOD CHALKY ROAD   \n",
       "190375                     PARTIGLIANO   \n",
       "191245                CHERRY  TREE  CT   \n",
       "193547                   THORN  STREET   \n",
       "194701                          TOOLEY   \n",
       "203041                   BRIARWOOD AVE   \n",
       "203042                   BRIARWOOD AVE   \n",
       "203043                   BRIARWOOD AVE   \n",
       "216567                          TAIMOR   \n",
       "216568                       TAIMOR ST   \n",
       "216927                   ELMONT  DRIVE   \n",
       "217529                      ELMONT DR.   \n",
       "220371           ROBINA TOWN CENTER DR   \n",
       "220407      LAUREN MEWS HAYLING ISLAND   \n",
       "220533                MILLER  BALLARAT   \n",
       "223243             FOXWOOD, CHALKY RD.   \n",
       "223334                   RUE DES LILAS   \n",
       "223335                   RUE DES LILAS   \n",
       "224720                      ELMONT DR.   \n",
       "225113   BLK 213 BATILE BATOK, STE 012   \n",
       "225794                        P.O. BOX   \n",
       "225795                        P.O. BOX   \n",
       "225796                        P.O. BOX   \n",
       "227074                   GLENNIE PLACE   \n",
       "227161  PINE LODGE, LOWOOD, ARMATHWAIT   \n",
       "227736                   CLUNE TERRACE   \n",
       "227737                   CLUNE TERRACE   \n",
       "227964                     ELMONT, DR.   \n",
       "...                                ...   \n",
       "244324                     ALBANY  HWY   \n",
       "244407             BUKIT BATOK CRESENT   \n",
       "244547     CORNER OF GRADUATE CRESCENT   \n",
       "244660     180,ON NUT S0135,SUKNHUMVIT   \n",
       "244661   180,ON NUT SOI  35  SUKHUMVIT   \n",
       "244799                  MASLISANSKY ST   \n",
       "244856                      NAVAHO DR.   \n",
       "244894                  WHITEGLEN CRES   \n",
       "244895                      NAVAHO DR.   \n",
       "245023              TURNER CLOSE CREWE   \n",
       "245024                    TURNER CREWE   \n",
       "245302                 BERKLEY CRES NW   \n",
       "245316                   ELMONT DR. SW   \n",
       "245957                      MAYNARD RD   \n",
       "245958                      MAYNARD RD   \n",
       "246218                  ABBOTS GARDENS   \n",
       "247060                         HAGALIL   \n",
       "247422                   DE 'I INFANTE   \n",
       "247515                         RADFORD   \n",
       "247907                    KNIGHT CLOSE   \n",
       "248034                    SASAMEMINAMI   \n",
       "248257         HORSESHOE WAY  UNIT 133   \n",
       "248379            BUKIT BATOK CRESCENT   \n",
       "248967                         TYNE ST   \n",
       "248968                         TYNE ST   \n",
       "249009         MANOR FARM,SOUTH NEWTON   \n",
       "249505             TENTH LIVERPOOL ST.   \n",
       "249762                   LAUNCESTON PL   \n",
       "249874                       CLADE ST.   \n",
       "250070            CRESCENT WCEGA TOWER   \n",
       "\n",
       "                                           city    zip_code country state  \n",
       "183911                           MANAMA HAHRAIN           0     USA   NaN  \n",
       "186126                    MISS, ONTARIO, CANADA     L5N 3H5     USA   NaN  \n",
       "188915                           STOCKBURG KENT           0     USA   NaN  \n",
       "190375                                    LUCCA       55067     USA   NaN  \n",
       "191245               CHARLESTON LONDON, ENGLAND     SE 770X     USA   NaN  \n",
       "193547                Woodville, United Kingdom    Deli-7DN     USA   NaN  \n",
       "194701                            LONDON SE12ET           0     USA   NaN  \n",
       "203041                 TORONTO  ONTARIO, CANADA      M9W6C9     USA   NaN  \n",
       "203042                 TORONTO  ONTARIO, CANADA      M9W6C9     USA   NaN  \n",
       "203043                 TORONTO  ONTARIO, CANADA      M9W6C9     USA   NaN  \n",
       "216567  ST. FATIMA SQ. HELIOPOLIS, CAIRO, EGYPT       11361    Egyp   NaN  \n",
       "216568  ST. FATIMA SQ. HELIOPOLIS, CAIRO, EGYPT       11361    Egyp   NaN  \n",
       "216927                 CALGARY, ALBERTA, CANADA     T3H-4X8    Cana   NaN  \n",
       "217529                 CALGARY, ALBERTA, CANADA     T3H-4X8    Cana   NaN  \n",
       "220371                              ROBINA  QLD        4226     USA   NaN  \n",
       "220407                           UNITED KINGDOM           0     USA   NaN  \n",
       "220533                                 VICTORIA        3350     USA   NaN  \n",
       "223243                         STOCKBURY,  KENT  ME9,7QR UK     USA   NaN  \n",
       "223334                     ALFORTEVILLE, FRANCE       94140     USA   NaN  \n",
       "223335                     ALFORTEVILLE, FRANCE       94140     USA   NaN  \n",
       "224720                          CALVARY ALBERTA           0     USA   NaN  \n",
       "225113                                SINGAPORE      650213     USA   NaN  \n",
       "225794                         BET ZAIT, ISRAEL       90815     USA   NaN  \n",
       "225795                         BET ZAIT, ISRAEL       90815     USA   NaN  \n",
       "225796                         BET ZAIT, ISRAEL       90815     USA   NaN  \n",
       "227074                          QUEANBEYAN, NSW        2620     USA   NaN  \n",
       "227161                        CARLISLE CUMBRIAN          49     USA   NaN  \n",
       "227736                               NEWTONMORE           0     USA   NaN  \n",
       "227737                               NEWTONMORE           0     USA   NaN  \n",
       "227964                          CALGARY ALBERTA           0     USA   NaN  \n",
       "...                                         ...         ...     ...   ...  \n",
       "244324                               MT. BARKER        6324     USA   NaN  \n",
       "244407                        WCEGA TOWER 03-74      658065     USA   NaN  \n",
       "244547                              BELIZE CITY           0     USA   NaN  \n",
       "244660                                  BANGKOK           0     USA   NaN  \n",
       "244661                                  BONGKOK           0     USA   NaN  \n",
       "244799                          RAMOT JERUSALEM       97225     USA   NaN  \n",
       "244856                                  TORONTO         222     USA   NaN  \n",
       "244894                            N. E. CALGARY           0     USA   NaN  \n",
       "244895                                  TORONTO          22     USA   NaN  \n",
       "245023                                 CHESHIRE           0     USA   NaN  \n",
       "245024                                 CHESHIRE           0     USA   NaN  \n",
       "245302                          CALGARY,ALBERTA           0     USA   NaN  \n",
       "245316                                  CALGARY           0     USA   NaN  \n",
       "245957                                  WALTHAM         179     USA   NaN  \n",
       "245958                                  WALTHAM         179     USA   NaN  \n",
       "246218                          LODON ,N2OJE,UK           0     USA   NaN  \n",
       "247060                      GANIC TIKVA ,ISRAEL       55900     USA   NaN  \n",
       "247422                                 WATERLOO        1401     USA   NaN  \n",
       "247515                                  ONTARIO         342     USA   NaN  \n",
       "247907                          NEW SOUTH WALES        2448     USA   NaN  \n",
       "248034                                TADA CITY     3350035     USA   NaN  \n",
       "248257                              RICHMOND BC           0     USA   NaN  \n",
       "248379                                SINGAPORE      658065     USA   NaN  \n",
       "248967       BOX HILL NORTH, VICTORIA AUSTRALIA        3129     USA   NaN  \n",
       "248968       BOX HILL NORTH, VICTORIA AUSTRALIA        3129     USA   NaN  \n",
       "249009                 SALISBURY,WILT,SP2, OQD,           0     USA   NaN  \n",
       "249505                                 ROSE BAY        2029     USA   NaN  \n",
       "249762                           UNITED KINGDOM         157     USA   NaN  \n",
       "249874                             BEULAH SOUTH        5067     USA   NaN  \n",
       "250070                              BUKIT BATOK      658065     USA   NaN  \n",
       "\n",
       "[93 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check some info when state values are NaN\n",
    "train[train.state.isnull()][['mailing_address_str_name','city','zip_code','country','state']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In order to correct the mismatches in cities and countries, search the name of the city from google map\n",
    "# and correct the name of the country manually. As you probably notice, there are a lot of cities not only \n",
    "# just mismatched but also erraneously spelled e.g) TOKO, OSKA, SUREY, VAN COUVER. \n",
    "\n",
    "# Below is the list of misspelled and mismatched cities. While iterating over each raw,\n",
    "# any of cities or countries in the list appears, replace the erraneous label on country column to correct label. If there\n",
    "# is nothing erraneous then label USA.\n",
    "\n",
    "def nation_conv(element):\n",
    "    \n",
    "    singapore = 'WCEGA|PLAZA|PENISULA PLAZA|PENISULA AVE|PENINSULA|PENINSALA PLAZA|SINAGAPORE|SUNGAPORE|SINGA PORE|SINGAPO|SINGAPORE|WCEGA TOWER|BUKIT BATOK|SANDY PALM|BATOK'\n",
    "    canada = 'SUN RIDGE|SURRY|RICHMOND, BC|RICHMOND|RICHMOND V7A4V3|VAN COUVER|EDMONTON|SUREY|YELLOWKNIFE|WINNIPEG MANTOBA|VANCOUVER|ALBERTA|CANADA|ONTARIO|TORONTO|RICHMOND BC|WINDSOR|CALGARY|ALDERGROVE'\n",
    "    israel = 'RAMOT|ISRAEL|RAANANA|KIRYAT MOZKIN|RAMOT JERUSALEM|RAMONT JERUSALEM'\n",
    "    uk = 'WARWICK|ROTHERHAM|PAIGNTON|ONCHAN ISLE OF MAN|NORTH PORTSMOUTH|TORTOLA|SHEFFIELD|SCARBOUROUGH|SCARBOROUGH|LANARKSHIRE|NEW CASTLE UPON TYM|MICKLEOVER|LANDONDERRY|DUNDALK|HERT FORDSHIRE|THORTON CLEVELEY\\'S|SWINDON|STAFFORDSHIRE|SOUTHERNESS|SOUTH PORT|CHINNOR ORON|CHELTENHAM|CHATHAM|BURY|CANTERBURY|CARLUKE|CHARLTON|FARNBOROUGH HANTS|CHURCH TOWN|HATFIELD|MANCHESTER|ESSEX|LANCASHIRE|WARKFIELD BERKSHIRE|WARFIELD BERKSHIRE|TRURO|BROMLEY|BRIGHT|BRIGHTON|BICKERLEY RINGWOOD|BERKSHIRE|SALISBURY|CARLISLE CUMBRIAN|UNITED KINGDOM|LONDON|ENGLAND|CHESHIRE|KENT|NEWTONMORE|UNITED KINGDO|ECKINGTON, SHEFFIELD|WISHAW|LODON ,N2OJE,UK|OJE|SALISBURY,WILT,SP2, OQD,'\n",
    "    egypt = 'NEW CIARO|EGYPT|ST FATIMA SQ HELIOP|CAIRO'\n",
    "    france = 'PARIS|FRANCE|ALQUE MORTES|MATISSE CHAMPS SUR'\n",
    "    thai = 'BANGKOK|THAILAND|BONGKOK'\n",
    "    australia = 'QUEENSLAND|SMYLHES CREEK|NEDLAND|FASSI FERN |BELLS BROOK|BULLSBRPPK|BULLSHROOK|BUNDALL|ELLES GROVE|CROYDON|CROSSOVER|COLDSTREAM|BULLSBROOK|BRISBANE OLD|BLACK TOWN|BELROSE|BASSENDEAN|AVALON CITY|ROBINA|QUEANBEYAN|NSW|AUSTRALIA|ROBINA QLD|AUSTRALI|VICTORIA|QUENSLAND|BOX HILL NORTH VICT|MT. BARKER|NEW SOUTH WALES|ROSE BAY'\n",
    "    bahrain = 'MANAMA'\n",
    "    italy = 'DI QUATIRO CA|LUCCA|ALZATE'\n",
    "    holland = 'VOORBURG|VEGHEL|NETHERLAND'\n",
    "    zealand = 'AUCKLAND|New Zealand'\n",
    "    japan = 'OSKA|KOMAE SHI|TOKYO|TOYKO|TOKO|JAPAN|CHIBA CITY'\n",
    "    china = 'TAI O|QINGXIU|QING XIU|NEW PRAYN|SHANGHAI|HONG KONG|TAIPEI|KWON TONG|KWUN TONG'\n",
    "    germany = 'WALDKRAIBURG|MUNICH|BERLIN'\n",
    "    india = 'SONEPAT HARYANA|ISLAMABAD'\n",
    "    arab = 'DUBAI'\n",
    "    malay = 'SUBANG JAYA|SALANGOR'\n",
    "    indonesia = 'SABANG JAYA'\n",
    "    lebanon = 'LEBANON'\n",
    "    nigiria = 'ALAUSA'\n",
    "    norway = 'NORWAY'\n",
    "    poland = 'POZNAN'\n",
    "    etc = 'TADA CITY|BEULAH SOUTH'\n",
    "    \n",
    "    nations = [singapore,canada,israel,uk,egypt,france,thai,australia,bahrain,italy,holland,zealand,japan,china,germany,india,arab,malay,indonesia,lebanon,nigiria,norway,poland,etc]\n",
    "    labels = ['SIN','CAN','ISR','UK','EGY','FRA','THI','AUS','BAH','ITA','HOL','NZL','JAP','CHN','GER','IND','ARA','MAL','IDN','LEB','NIG','NOR','POL','ETC']\n",
    "    \n",
    "    # If we create a dictionary, labeling would be so much easier.\n",
    "    code = dict.fromkeys([])\n",
    "    \n",
    "    for nation, label in zip(nations,labels):\n",
    "        code.update(dict.fromkeys(nation.split('|'), label))\n",
    "    \n",
    "    for nation in nations:\n",
    "        found = list(map(lambda x: x.upper(),re.findall('\\\\b' + nation + '\\\\b', element, re.IGNORECASE)))\n",
    "        if(len(found) > 0):\n",
    "            return code[found[0]]\n",
    "        continue\n",
    "    \n",
    "    return 'USA'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>agency_name</th>\n",
       "      <th>inspector_name</th>\n",
       "      <th>violator_name</th>\n",
       "      <th>mailing_address_str_number</th>\n",
       "      <th>mailing_address_str_name</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>country</th>\n",
       "      <th>...</th>\n",
       "      <th>fine_amount</th>\n",
       "      <th>admin_fee</th>\n",
       "      <th>state_fee</th>\n",
       "      <th>late_fee</th>\n",
       "      <th>discount_amount</th>\n",
       "      <th>clean_up_cost</th>\n",
       "      <th>judgment_amount</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>num_null</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12495</th>\n",
       "      <td>306086</td>\n",
       "      <td>Department of Public Works</td>\n",
       "      <td>May, Tanya</td>\n",
       "      <td>CHASE HOME FINANCE LLC, .</td>\n",
       "      <td>8</td>\n",
       "      <td>BROOKSEDGE BLVD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OH</td>\n",
       "      <td>43081</td>\n",
       "      <td>USA</td>\n",
       "      <td>...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>42.411773</td>\n",
       "      <td>-83.155902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ticket_id                 agency_name inspector_name  \\\n",
       "12495     306086  Department of Public Works     May, Tanya   \n",
       "\n",
       "                   violator_name mailing_address_str_number  \\\n",
       "12495  CHASE HOME FINANCE LLC, .                          8   \n",
       "\n",
       "      mailing_address_str_name city state zip_code country    ...     \\\n",
       "12495          BROOKSEDGE BLVD  NaN    OH    43081     USA    ...      \n",
       "\n",
       "      fine_amount admin_fee state_fee late_fee discount_amount  clean_up_cost  \\\n",
       "12495       200.0      20.0      10.0     20.0             0.0            0.0   \n",
       "\n",
       "       judgment_amount        lat        lon  num_null  \n",
       "12495            250.0  42.411773 -83.155902         1  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test['city'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned before, there are a lot of incorrect information on country column. Consequently, it is necessary to createa new column by applying the above function 'nation_conv' for describing violator's mailing country. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Apply the function.\n",
    "train['new_country'] = train['city'].map(nation_conv)\n",
    "\n",
    "# Based on google map, the name of the city in test dataset considered as a missing value is actually Westerville,\n",
    "# which matches with the state and street name and zipcode.\n",
    "test.city.fillna('NULL', inplace=True)\n",
    "test.city.iloc[12495] = 'Westerville'\n",
    "\n",
    "# Apply the function on test set. \n",
    "test['new_country'] = test['city'].map(nation_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Some name of cities, for example WATERLOO, VICTORIA, are used widely in english-speaking countries. Therefore,\n",
    "# in order to avoid misclassification, manually label those cities by using google map. In addition, as mentioned, there\n",
    "# are some places that cannot be found in google map and label them as ETC.\n",
    "\n",
    "# Training Set:\n",
    "# city: WATERLOO, BELGIUM\n",
    "train['new_country'].iloc[236844] = 'BEL'\n",
    "train['new_country'].iloc[247422] = 'BEL'\n",
    "\n",
    "# city: BEVAN WAY ABBOTSFORD B.C V256R3\n",
    "train['new_country'].iloc[240635] = 'CAN'\n",
    "train['new_country'].iloc[240806] = 'CAN'\n",
    "\n",
    "# city: BELIZE CITY\n",
    "train['new_country'].iloc[244547] = 'BLZ'\n",
    "\n",
    "# Test Set:\n",
    "#city: BELIZE CITY\n",
    "test['new_country'].iloc[4328] = 'BLZ'\n",
    "\n",
    "# UNITED KINGDOM\n",
    "test['new_country'].iloc[20878] = 'UK'\n",
    "test['new_country'].iloc[5647] = 'UK'\n",
    "test['new_country'].iloc[5648] = 'UK'\n",
    "test['new_country'].iloc[17870] = 'UK'\n",
    "test['new_country'].iloc[17871] = 'UK'\n",
    "test['new_country'].iloc[16513] = 'UK'\n",
    "test['new_country'].iloc[21689] = 'UK'\n",
    "test['new_country'].iloc[22436] = 'UK'\n",
    "test['new_country'].iloc[22268] = 'UK'\n",
    "test['new_country'].iloc[17911] = 'JAP'\n",
    "\n",
    "# ETC list (failed to find the exact locations by google)\n",
    "test['new_country'].iloc[14051] = 'ETC'\n",
    "test['new_country'].iloc[14050] = 'ETC'\n",
    "test['new_country'].iloc[22103] = 'ETC'\n",
    "test['new_country'].iloc[14308] = 'ETC'\n",
    "test['new_country'].iloc[2482] = 'ETC'\n",
    "test['new_country'].iloc[18154] = 'ETC'\n",
    "test['new_country'].iloc[10523] = 'ETC'\n",
    "test['new_country'].iloc[568] = 'ETC'\n",
    "test['new_country'].iloc[8580] = 'ETC'\n",
    "test['new_country'].iloc[19819] = 'ETC'\n",
    "test['new_country'].iloc[10857] = 'ETC'\n",
    "test['new_country'].iloc[21689] = 'ETC'\n",
    "test['new_country'].iloc[16413] = 'ETC'\n",
    "test['new_country'].iloc[3087] = 'ETC'\n",
    "test['new_country'].iloc[10656] = 'ETC'\n",
    "test['new_country'].iloc[13203] = 'ETC'\n",
    "test['new_country'].iloc[12860] = 'ETC'\n",
    "test['new_country'].iloc[19478] = 'ETC'\n",
    "test['new_country'].iloc[19479] = 'ETC'\n",
    "test['new_country'].iloc[5656] = 'ETC'\n",
    "test['new_country'].iloc[10776] = 'ETC'\n",
    "test['new_country'].iloc[19061] = 'ETC'\n",
    "\n",
    "# MAYNARD RD, WALTHAM : MA \n",
    "train.state.iloc[[245957,245958]] = 'MA'\n",
    "test.state.iloc[20598] = 'DE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If mailing addresses are not domestic, change them to 'OOS' which stands for out of states.\n",
    "\n",
    "train.state[train['new_country'] != 'USA'] = 'OOS'\n",
    "test.state[test['new_country'] != 'USA'] = 'OOS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique city names in training set: 5184\n",
      "unique city names in test set: 3266\n"
     ]
    }
   ],
   "source": [
    "# Let's see how many unique names in city column.\n",
    "\n",
    "print('unique city names in training set:',len(set(train.city)))\n",
    "print('unique city names in test set:',len(set(test.city)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# It appears that some values are duplicated due to extra space or upper or lower case difference even though they are\n",
    "# the same.\n",
    "\n",
    "train.city = train.city.apply(lambda x: x.upper().strip())\n",
    "test.city = test.city.apply(lambda x: x.upper().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique city names in training set: 4322\n",
      "unique city names in test set: 2694\n"
     ]
    }
   ],
   "source": [
    "# As you can see the results, we could greatly reduce the number of duplications.\n",
    "\n",
    "print('unique city names in training set:',len(set(train.city)))\n",
    "print('unique city names in test set:',len(set(test.city)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Zip_code for non-us countries: 'OOS'\n",
    "\n",
    "train.zip_code[train.new_country != 'USA'] = 'OOS'\n",
    "test.zip_code[test.new_country != 'USA'] = 'OOS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The rows whose state column value is NaN should be converted to string type since machine learning algorithms cannot \n",
    "# take in None type as input. Especially in this case, we cannot not even infer any of city, state and zip_code by the given\n",
    "# information (e.g mailing_address_str_name) label them 'NULL'. \n",
    "\n",
    "null_city_index = train[train.state.isnull()].index\n",
    "train['city'].iloc[null_city_index] = 'NULL'\n",
    "train['zip_code'].iloc[null_city_index] = 'NULL'\n",
    "train['state'].iloc[null_city_index] = 'NULL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ON', 'VI', 'OOS', 'NB', 'NULL', 'BC', 'BL', 'PR', 'QL', 'UK', 'QC']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ON', 'VI', 'NB', 'BC', 'BL', 'PR', 'QL', 'UK', 'QC']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there is any states other than us states in state columns.\n",
    "\n",
    "us_state = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"FL\", \"GA\", \n",
    "          \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \n",
    "          \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \n",
    "          \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \n",
    "          \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]\n",
    "\n",
    "not_us_state = []\n",
    "all_state = set(train.state)|set(test.state)\n",
    "\n",
    "for a in all_state:\n",
    "    if(a not in us_state):\n",
    "        not_us_state.append(a)\n",
    "\n",
    "        \n",
    "print(not_us_state)\n",
    "\n",
    "# Make sure that exclude 'OOS' and 'NULL'\n",
    "not_us_state.remove('OOS')\n",
    "not_us_state.remove('NULL')\n",
    "\n",
    "not_us_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Below rows are wrong abbreviation for the state.\n",
    "\n",
    "# According to google map, the state of this row supposed to be Virgina VA not VI.\n",
    "# Since the rest of VI represents Virgin Island in US so remove VI from not_us_state list\n",
    "train.state.iloc[15713] = 'VA'\n",
    "not_us_state.remove('VI')\n",
    "\n",
    "# According to google map, the state of this row supposed to be Nevada NV not NB.\n",
    "train.state.iloc[181834] = 'NV'\n",
    "train.state.iloc[181835] = 'NV'\n",
    "\n",
    "# Most of states denoted as 'NB' supposed to be 'NE'; therefore, from the not_us_state list, we need to remove it \n",
    "# to avoid an error when we create the dictionary later on. NB also stands for New Brunswick which is the province in \n",
    "# Canada but decide not to manually alter since the number of rows actually New Brunswick is negligible.\n",
    "\n",
    "train.state[train.state == 'NB'] = 'NE'\n",
    "test.state[test.state == 'NB'] = 'NE'\n",
    "\n",
    "not_us_state.remove('NB')\n",
    "\n",
    "# Many rows are wrongly classified as USA. \n",
    "train.state.iloc[248498] = 'OOS'\n",
    "train.new_country.iloc[248498] = 'SIN'\n",
    "train.state.iloc[241977] = 'OOS'\n",
    "train.new_country.iloc[241977] = 'SIN'\n",
    "\n",
    "train.state.iloc[107274] = 'OOS'\n",
    "train.new_country.iloc[107274] = 'CAN'\n",
    "train.state.iloc[107275] = 'OOS'\n",
    "train.new_country.iloc[107275] = 'CAN'\n",
    "\n",
    "train.state.iloc[20801] = 'OOS'\n",
    "train.new_country.iloc[20801] = 'CHN'\n",
    "train.state.iloc[20802] = 'OOS'\n",
    "train.new_country.iloc[20802] = 'CHN'\n",
    "\n",
    "#test.state.iloc[338993] = 'OOS'\n",
    "#test.new_country.iloc[338993] = 'JAP'\n",
    "#test.state.iloc[338995] = 'OOS'\n",
    "#test.new_country.iloc[338995] = 'JAP'\n",
    "\n",
    "test.state.iloc[6550] = 'OOS'\n",
    "test.new_country.iloc[6550] = 'JAP'\n",
    "\n",
    "test.state.iloc[6551] = 'OOS'\n",
    "test.new_country.iloc[6551] = 'JAP'\n",
    "\n",
    "test.state.iloc[9266] = 'OOS'\n",
    "test.new_country.iloc[9266] = 'JAP'\n",
    "\n",
    "#test.state.iloc[357567] = 'OOS'\n",
    "#test.new_country.iloc[357567] = 'SIN'\n",
    "\n",
    "test.state.iloc[33881] = 'OOS'\n",
    "test.new_country.iloc[33881] = 'SIN'\n",
    "test.state.iloc[2736] = 'OOS'\n",
    "test.new_country.iloc[2736] = 'SIN'\n",
    "test.state.iloc[3570] = 'OOS'\n",
    "test.new_country.iloc[3570] = 'ETC'\n",
    "test.state.iloc[5427] = 'OOS'\n",
    "test.new_country.iloc[5427] = 'ETC'\n",
    "test.state.iloc[11289] = 'OOS'\n",
    "test.new_country.iloc[11289] = 'ETC'\n",
    "test.state.iloc[20175] = 'OOS'\n",
    "test.new_country.iloc[20175] = 'ETC'\n",
    "test.state.iloc[20176] = 'OOS'\n",
    "test.new_country.iloc[20176] = 'ETC'\n",
    "test.state.iloc[20234] = 'OOS'\n",
    "test.new_country.iloc[20234] = 'ETC'\n",
    "\n",
    "test.state.iloc[34188] = 'OOS'\n",
    "test.new_country.iloc[34188] = 'CAN'\n",
    "test.state.iloc[34189] = 'OOS'\n",
    "test.new_country.iloc[34189] = 'CAN'\n",
    "\n",
    "test.state.iloc[48595] = 'OOS'\n",
    "test.new_country.iloc[48595] = 'AUS'\n",
    "test.state.iloc[48596] = 'OOS'\n",
    "test.new_country.iloc[48596] = 'AUS'\n",
    "\n",
    "# The country denoted as USA but has non-us states in state column should be converted to the proper labels.\n",
    "nation_map = dict.fromkeys(['BC','ON','QC'],'CAN')\n",
    "nation_map['BL'] = 'GER'\n",
    "nation_map['UK'] = 'UK'\n",
    "nation_map['QL'] = 'AUS'\n",
    "nation_map['PR'] = 'ETC'\n",
    "\n",
    "for st in set(not_us_state):\n",
    "    train.new_country[train.state == st] = nation_map[st]\n",
    "    test.new_country[test.state == st] = nation_map[st]\n",
    "    \n",
    "    train.state[train.state == st] = 'OOS'\n",
    "    test.state[test.state == st] = 'OOS'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of states in training set: 54\n",
      "# of states in test set: 53\n"
     ]
    }
   ],
   "source": [
    "# Including NULL and OOS ('Out of States'), there should be 54 states in training set and 53 states in test set (no NULL value).\n",
    "\n",
    "print('# of states in training set:',len(set(train.state)))\n",
    "print('# of states in test set:',len(set(test.state)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Some rows whose city column has ST THOMAS are classified as VA which supposed to be VI (Virgin Irland)\n",
    "va_island = train[train.state == 'VA'].city.str.extractall(r'(.* THOMAS)').index.levels[0]\n",
    "train.state.iloc[va_island] = 'VI'\n",
    "\n",
    "va_island_test = test[test.state == 'VA'].city.str.extractall(r'(.* THOMAS)').index.levels[0]\n",
    "test.state.iloc[va_island_test] = 'VI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.15 Zip Code\n",
    "\n",
    "Zipcode column comprises string and integer; therefore, first thing to do is to convert all the zipcode to string. Also, simplify the international zipcodes as OOS 'Out Of States'. If there is invalid place cannot be found even in google map, then label them as 'NULL'. In addition, we could find many invalid zipcode which consist of three digits or less. These should be also converted to 'NULL'. Lastly, remove hyphen sign which connects main zipcode (usually 5 digits) between detail zipcodes for unity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Need to standardized the zip_code type. (Some of them are string and some of them are integer)\n",
    "\n",
    "train.zip_code = train.zip_code.apply(lambda x: str(x))\n",
    "test.zip_code = test.zip_code.apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Zipcode for Out of states is OOS\n",
    "\n",
    "train.zip_code[train.state == 'OOS'] = 'OOS'\n",
    "test.zip_code[test.state == 'OOS'] = 'OOS'\n",
    "\n",
    "# US zipcode whose default value is 0 changes to NULL\n",
    "\n",
    "train.zip_code[((train.zip_code == '0') | (train.zip_code == 0)) & (train.new_country == 'USA')] = 'NULL'\n",
    "test.zip_code[((test.zip_code == '0') | (test.zip_code == 0)) & (test.new_country == 'USA')] = 'NULL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find wrong format zipcode which consists from 0 to 3 digits. We can safely assume that upto 3 digits zipcode\n",
    "# are wrong type format; even though 4 digits can be problematic as well, the case starts with 0 postal code can be\n",
    "# 5 digits only if the type is string. ex) 04513. \n",
    "\n",
    "train.zip_code[train.zip_code.str.match(r'^([0-9]{0,3})?$')] = 'NULL'\n",
    "test.zip_code[test.zip_code.str.match(r'^([0-9]{0,3})?$')] = 'NULL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Unify the format of 9 digits or 8 digits postal code as non-hyphen(or non-special characters) postal code. \n",
    "# ex) 12345-6789 => 123456789\n",
    "\n",
    "train.zip_code = train.zip_code.apply(lambda x: re.sub('[^A-Za-z0-9]','',x))\n",
    "test.zip_code = test.zip_code.apply(lambda x: re.sub('[^A-Za-z0-9]','',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.16 Hearing Date\n",
    "\n",
    "The reason why I chose to treate the hearing date column as nominal rather than interval is that hearing time has only 6 unique values which can be easier to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill missing values with xxxx-xx-xx xx:xx:xx.\n",
    "\n",
    "train.hearing_date.fillna('xxxx-xx-xx xx:xx:xx', inplace=True)\n",
    "test.hearing_date.fillna('xxxx-xx-xx xx:xx:xx', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split hearing dates by four: YR, MM, DD, time\n",
    "\n",
    "train['HR_YR'] = train.hearing_date.apply(lambda x:x.split()[0].split('-')[0])\n",
    "train['HR_MO'] = train.hearing_date.apply(lambda x:x.split()[0].split('-')[1])\n",
    "train['HR_DD'] = train.hearing_date.apply(lambda x:x.split()[0].split('-')[2])\n",
    "\n",
    "train['HR_time'] = train.hearing_date.apply(lambda x:x.split( )[1])\n",
    "\n",
    "test['HR_YR'] = test.hearing_date.apply(lambda x:x.split()[0].split('-')[0])\n",
    "test['HR_MO'] = test.hearing_date.apply(lambda x:x.split()[0].split('-')[1])\n",
    "test['HR_DD'] = test.hearing_date.apply(lambda x:x.split()[0].split('-')[2])\n",
    "\n",
    "test['HR_time'] = test.hearing_date.apply(lambda x:x.split( )[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.17 Ticket Issued Date\n",
    "\n",
    "Year, month, and day of the ticket issued date are treated as hearing date column except for the time part. Unlike the hearing time, it should be converted to minute basis to treat as interval type since it increases every 5 minutes, which can be too many if we create binary columns by pd.get_dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split ticket issued date by four: YR, MM, DD, time\n",
    "\n",
    "train['TI_YR'] = train.ticket_issued_date.apply(lambda x:x.split()[0].split('-')[0])\n",
    "train['TI_MO'] = train.ticket_issued_date.apply(lambda x:x.split()[0].split('-')[1])\n",
    "train['TI_DD'] = train.ticket_issued_date.apply(lambda x:x.split()[0].split('-')[2])\n",
    "\n",
    "train['TI_MI'] = train.ticket_issued_date.apply(lambda x:int(x.split()[1].split(':')[0])*60 + int(x.split()[1].split(':')[1]))\n",
    "\n",
    "#train['TI_HR'] = train.ticket_issued_date.apply(lambda x:int(x.split()[1].split(':')[0]))\n",
    "#train['TI_MI'] = train.ticket_issued_date.apply(lambda x:int(x.split()[1].split(':')[1]))\n",
    "\n",
    "test['TI_YR'] = test.ticket_issued_date.apply(lambda x:x.split()[0].split('-')[0])\n",
    "test['TI_MO'] = test.ticket_issued_date.apply(lambda x:x.split()[0].split('-')[1])\n",
    "test['TI_DD'] = test.ticket_issued_date.apply(lambda x:x.split()[0].split('-')[2])\n",
    "\n",
    "test['TI_MI'] = test.ticket_issued_date.apply(lambda x:int(x.split()[1].split(':')[0])*60 + int(x.split()[1].split(':')[1]))\n",
    "#train['TI_HR'] = test.ticket_issued_date.apply(lambda x:int(x.split()[1].split(':')[0]))\n",
    "#train['TI_MI'] = test.ticket_issued_date.apply(lambda x:int(x.split()[1].split(':')[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.18 Violation Code / Violation Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>violation_code</th>\n",
       "      <th>violation_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9-1-36(a)</td>\n",
       "      <td>Failure of owner to obtain certificate of comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61-63.0600</td>\n",
       "      <td>Failed To Secure Permit For Lawful Use Of Buil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9-1-36(a)</td>\n",
       "      <td>Failure of owner to obtain certificate of comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9-1-36(a)</td>\n",
       "      <td>Failure of owner to obtain certificate of comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9-1-36(a)</td>\n",
       "      <td>Failure of owner to obtain certificate of comp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  violation_code                              violation_description\n",
       "0      9-1-36(a)  Failure of owner to obtain certificate of comp...\n",
       "1     61-63.0600  Failed To Secure Permit For Lawful Use Of Buil...\n",
       "2      9-1-36(a)  Failure of owner to obtain certificate of comp...\n",
       "3      9-1-36(a)  Failure of owner to obtain certificate of comp...\n",
       "4      9-1-36(a)  Failure of owner to obtain certificate of comp..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['violation_code','violation_description']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see some duplicated values, violation codes and descriptions are corresponding each other, which means we can eliminate violation_description column at the end of the preprocessing. (e.g 9-1-36(a) -> Failure of owner to obtain certificate of comp...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.19 Fine Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>violation_code</th>\n",
       "      <th>violation_description</th>\n",
       "      <th>disposition</th>\n",
       "      <th>fine_amount</th>\n",
       "      <th>admin_fee</th>\n",
       "      <th>state_fee</th>\n",
       "      <th>late_fee</th>\n",
       "      <th>discount_amount</th>\n",
       "      <th>clean_up_cost</th>\n",
       "      <th>judgment_amount</th>\n",
       "      <th>...</th>\n",
       "      <th>num_null</th>\n",
       "      <th>new_country</th>\n",
       "      <th>HR_YR</th>\n",
       "      <th>HR_MO</th>\n",
       "      <th>HR_DD</th>\n",
       "      <th>HR_time</th>\n",
       "      <th>TI_YR</th>\n",
       "      <th>TI_MO</th>\n",
       "      <th>TI_DD</th>\n",
       "      <th>TI_MI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81440</th>\n",
       "      <td>22-2-88</td>\n",
       "      <td>Failure of owner to keep property, its sidewal...</td>\n",
       "      <td>Not responsible by Dismissal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>USA</td>\n",
       "      <td>2007</td>\n",
       "      <td>01</td>\n",
       "      <td>29</td>\n",
       "      <td>13:30:00</td>\n",
       "      <td>2007</td>\n",
       "      <td>01</td>\n",
       "      <td>03</td>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      violation_code                              violation_description  \\\n",
       "81440        22-2-88  Failure of owner to keep property, its sidewal...   \n",
       "\n",
       "                        disposition  fine_amount  admin_fee  state_fee  \\\n",
       "81440  Not responsible by Dismissal          NaN        0.0        0.0   \n",
       "\n",
       "       late_fee  discount_amount  clean_up_cost  judgment_amount  ...   \\\n",
       "81440       0.0              0.0            0.0              0.0  ...    \n",
       "\n",
       "       num_null  new_country  HR_YR  HR_MO HR_DD   HR_time TI_YR TI_MO TI_DD  \\\n",
       "81440         2          USA   2007     01    29  13:30:00  2007    01    03   \n",
       "\n",
       "      TI_MI  \n",
       "81440   795  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As you can see below, there is one missing value in training fine amount column (no missing value in test set).\n",
    "train[train.fine_amount.isnull()].iloc[:,12:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({200.0: 1729, 3500.0: 1100, 1000.0: 875, 500.0: 722, 2500.0: 503, 10000.0: 59, 5000.0: 30, 345.0: 2, nan: 1})\n"
     ]
    }
   ],
   "source": [
    "# Although I searched rows of the fine amount that shares the same violation code and disposition \n",
    "# in order to fill the missing value with reasonable amount, there is no common value. \n",
    "\n",
    "print(Counter(train[(train.violation_code == '22-2-88') & (train.disposition == 'Not responsible by Dismissal')].iloc[:,15:].fine_amount))\n",
    "\n",
    "# Therefore, decided to use the most frequent fine amount 200.0 to fill the missing value.\n",
    "\n",
    "train.fine_amount.fillna(200.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.20 Redundant Columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ticket_id',\n",
       " 'agency_name',\n",
       " 'inspector_name',\n",
       " 'violator_name',\n",
       " 'mailing_address_str_number',\n",
       " 'mailing_address_str_name',\n",
       " 'city',\n",
       " 'state',\n",
       " 'zip_code',\n",
       " 'country',\n",
       " 'ticket_issued_date',\n",
       " 'hearing_date',\n",
       " 'violation_code',\n",
       " 'violation_description',\n",
       " 'disposition',\n",
       " 'fine_amount',\n",
       " 'admin_fee',\n",
       " 'state_fee',\n",
       " 'late_fee',\n",
       " 'discount_amount',\n",
       " 'clean_up_cost',\n",
       " 'judgment_amount',\n",
       " 'compliance',\n",
       " 'lat',\n",
       " 'lon',\n",
       " 'num_null',\n",
       " 'new_country',\n",
       " 'HR_YR',\n",
       " 'HR_MO',\n",
       " 'HR_DD',\n",
       " 'HR_time',\n",
       " 'TI_YR',\n",
       " 'TI_MO',\n",
       " 'TI_DD',\n",
       " 'TI_MI']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at what columns are left.\n",
    "list(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "redundant = ['violator_name','mailing_address_str_number','mailing_address_str_name','city','country','violation_description','num_null','hearing_date','ticket_issued_date']\n",
    "train.drop(redundant, inplace = True, axis = 1)\n",
    "test.drop(redundant, inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__hearing_date, ticket_issued_date__: Since we already split the time of these two columns in detail so they are not needed.<br>\n",
    "__num_null__: As mentioned, this column is created for the convenience to check how many missing values in each row for preprocessing. For the later process, it is not needed.<br>\n",
    "__mailing_address_str_name, mailing_address_str_number, violator_name, city__: There are too many unique values and too many typos to use them as machine learning algorithms' input.<br>\n",
    "__country__: Many values are wronly classified, for example, the label supposed to be USA but Canada or vice versa.<br>\n",
    "__violation_description__: It is tanamount to violation_code, just violation_description is described as english and violation_code is encoded; however, violation_code is much easier to display so decided to remove 'violation_description' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.21 Compliance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment, our task is to predict whether a given blight ticket will be paid on time. Therefore, all we want to know is to 'will be paid on time' or not. Label 1 if the ticket will be paid on time. Otherwise, label 0 (Fill missing values with 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.compliance.fillna(0.0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Also for modeling purpose, split the column from training set.\n",
    "\n",
    "y = train.compliance.astype(int)\n",
    "train.drop('compliance',axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.22 Ticket ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ticket ID for test is important for the final result. It will be used for index of our final prediction.\n",
    "\n",
    "test_id = test.ticket_id\n",
    "test.drop('ticket_id',axis=1, inplace=True)\n",
    "\n",
    "train_id = train.ticket_id\n",
    "train.drop('ticket_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.23 Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.231 Nominal Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency_name</th>\n",
       "      <th>inspector_name</th>\n",
       "      <th>state</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>violation_code</th>\n",
       "      <th>disposition</th>\n",
       "      <th>fine_amount</th>\n",
       "      <th>admin_fee</th>\n",
       "      <th>state_fee</th>\n",
       "      <th>late_fee</th>\n",
       "      <th>...</th>\n",
       "      <th>lon</th>\n",
       "      <th>new_country</th>\n",
       "      <th>HR_YR</th>\n",
       "      <th>HR_MO</th>\n",
       "      <th>HR_DD</th>\n",
       "      <th>HR_time</th>\n",
       "      <th>TI_YR</th>\n",
       "      <th>TI_MO</th>\n",
       "      <th>TI_DD</th>\n",
       "      <th>TI_MI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Buildings, Safety Engineering &amp; Env Department</td>\n",
       "      <td>Sims, Martinzie</td>\n",
       "      <td>IL</td>\n",
       "      <td>60606</td>\n",
       "      <td>9-1-36(a)</td>\n",
       "      <td>Responsible by Default</td>\n",
       "      <td>250.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-83.124268</td>\n",
       "      <td>USA</td>\n",
       "      <td>2005</td>\n",
       "      <td>03</td>\n",
       "      <td>21</td>\n",
       "      <td>10:30:00</td>\n",
       "      <td>2004</td>\n",
       "      <td>03</td>\n",
       "      <td>16</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Buildings, Safety Engineering &amp; Env Department</td>\n",
       "      <td>Williams, Darrin</td>\n",
       "      <td>MI</td>\n",
       "      <td>48208</td>\n",
       "      <td>61-63.0600</td>\n",
       "      <td>Responsible by Determination</td>\n",
       "      <td>750.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-83.135118</td>\n",
       "      <td>USA</td>\n",
       "      <td>2005</td>\n",
       "      <td>05</td>\n",
       "      <td>06</td>\n",
       "      <td>13:30:00</td>\n",
       "      <td>2004</td>\n",
       "      <td>04</td>\n",
       "      <td>23</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Buildings, Safety Engineering &amp; Env Department</td>\n",
       "      <td>Sims, Martinzie</td>\n",
       "      <td>MI</td>\n",
       "      <td>48223</td>\n",
       "      <td>9-1-36(a)</td>\n",
       "      <td>Not responsible by Dismissal</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-83.096069</td>\n",
       "      <td>USA</td>\n",
       "      <td>2005</td>\n",
       "      <td>03</td>\n",
       "      <td>29</td>\n",
       "      <td>10:30:00</td>\n",
       "      <td>2004</td>\n",
       "      <td>04</td>\n",
       "      <td>26</td>\n",
       "      <td>820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Buildings, Safety Engineering &amp; Env Department</td>\n",
       "      <td>Sims, Martinzie</td>\n",
       "      <td>MI</td>\n",
       "      <td>48214</td>\n",
       "      <td>9-1-36(a)</td>\n",
       "      <td>Not responsible by City Dismissal</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-83.095919</td>\n",
       "      <td>USA</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>xx</td>\n",
       "      <td>xx</td>\n",
       "      <td>xx:xx:xx</td>\n",
       "      <td>2004</td>\n",
       "      <td>04</td>\n",
       "      <td>26</td>\n",
       "      <td>810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Buildings, Safety Engineering &amp; Env Department</td>\n",
       "      <td>Sims, Martinzie</td>\n",
       "      <td>MI</td>\n",
       "      <td>48206</td>\n",
       "      <td>9-1-36(a)</td>\n",
       "      <td>Not responsible by Dismissal</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-83.208233</td>\n",
       "      <td>USA</td>\n",
       "      <td>2005</td>\n",
       "      <td>03</td>\n",
       "      <td>29</td>\n",
       "      <td>10:30:00</td>\n",
       "      <td>2004</td>\n",
       "      <td>04</td>\n",
       "      <td>26</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      agency_name    inspector_name state  \\\n",
       "0  Buildings, Safety Engineering & Env Department   Sims, Martinzie    IL   \n",
       "1  Buildings, Safety Engineering & Env Department  Williams, Darrin    MI   \n",
       "2  Buildings, Safety Engineering & Env Department   Sims, Martinzie    MI   \n",
       "3  Buildings, Safety Engineering & Env Department   Sims, Martinzie    MI   \n",
       "4  Buildings, Safety Engineering & Env Department   Sims, Martinzie    MI   \n",
       "\n",
       "  zip_code violation_code                        disposition  fine_amount  \\\n",
       "0    60606      9-1-36(a)             Responsible by Default        250.0   \n",
       "1    48208     61-63.0600       Responsible by Determination        750.0   \n",
       "2    48223      9-1-36(a)       Not responsible by Dismissal        250.0   \n",
       "3    48214      9-1-36(a)  Not responsible by City Dismissal        250.0   \n",
       "4    48206      9-1-36(a)       Not responsible by Dismissal        250.0   \n",
       "\n",
       "   admin_fee  state_fee  late_fee  ...         lon  new_country  HR_YR  HR_MO  \\\n",
       "0       20.0       10.0      25.0  ...  -83.124268          USA   2005     03   \n",
       "1       20.0       10.0      75.0  ...  -83.135118          USA   2005     05   \n",
       "2        0.0        0.0       0.0  ...  -83.096069          USA   2005     03   \n",
       "3        0.0        0.0       0.0  ...  -83.095919          USA   xxxx     xx   \n",
       "4        0.0        0.0       0.0  ...  -83.208233          USA   2005     03   \n",
       "\n",
       "   HR_DD   HR_time TI_YR TI_MO TI_DD TI_MI  \n",
       "0     21  10:30:00  2004    03    16   700  \n",
       "1     06  13:30:00  2004    04    23   750  \n",
       "2     29  10:30:00  2004    04    26   820  \n",
       "3     xx  xx:xx:xx  2004    04    26   810  \n",
       "4     29  10:30:00  2004    04    26   780  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ordinal_list = list(train.dtypes[train.dtypes=='object'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['agency_name', 'inspector_name', 'state', 'zip_code', 'violation_code', 'disposition', 'new_country', 'HR_YR', 'HR_MO', 'HR_DD', 'HR_time', 'TI_YR', 'TI_MO', 'TI_DD']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5, 173, 54, 4111, 235, 9, 18, 13, 13, 32, 6, 11, 12, 31]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ordinal_list)\n",
    "list(map(lambda x: len(set(train[x])),ordinal_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list above is the length of each ordinal variable's unique value. Among many numbers, 4112 is noteceable which comes from 'zip_code' column. In order to work ordinal variables in machine learning algorithms, they must be binarized; however, in the process of binarization, the number of columns increases as the number of unique values in the original column, which can cause increasing variance of the model. This leads to overfitting.<br>\n",
    "As a rule of thumb for a number of features, if we assume that variables are theoretically (perfectly) not correlated each other, N (number of samples) - 1 is allowable. If variables are perfectly correlated, N^(1/2) is the desirable number of features. If we follow this logic, as mentioned, zipcode can be potential threat to overfitting. Besides, 'zip_code' is not the only variable to represent geographical information but 'state' column (mailing_state) can represent where the violator's mailing address is. Therefore, I decide to remove 'zip_code' column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.drop('zip_code',axis=1, inplace=True)\n",
    "test.drop('zip_code',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "612"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinal_list.remove('zip_code')\n",
    "sum(list(map(lambda x: len(set(train[x])), ordinal_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we binarize the nominal variables, check the types of each columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agency_name         object\n",
       "inspector_name      object\n",
       "state               object\n",
       "violation_code      object\n",
       "disposition         object\n",
       "fine_amount        float64\n",
       "admin_fee          float64\n",
       "state_fee          float64\n",
       "late_fee           float64\n",
       "discount_amount    float64\n",
       "clean_up_cost      float64\n",
       "judgment_amount    float64\n",
       "lat                float64\n",
       "lon                float64\n",
       "new_country         object\n",
       "HR_YR               object\n",
       "HR_MO               object\n",
       "HR_DD               object\n",
       "HR_time             object\n",
       "TI_YR               object\n",
       "TI_MO               object\n",
       "TI_DD               object\n",
       "TI_MI                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True], dtype=bool)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if two datasets have same columns.\n",
    "train.columns == test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "agency_name        True\n",
       "inspector_name     True\n",
       "state              True\n",
       "violation_code     True\n",
       "disposition        True\n",
       "fine_amount        True\n",
       "admin_fee          True\n",
       "state_fee          True\n",
       "late_fee           True\n",
       "discount_amount    True\n",
       "clean_up_cost      True\n",
       "judgment_amount    True\n",
       "lat                True\n",
       "lon                True\n",
       "new_country        True\n",
       "HR_YR              True\n",
       "HR_MO              True\n",
       "HR_DD              True\n",
       "HR_time            True\n",
       "TI_YR              True\n",
       "TI_MO              True\n",
       "TI_DD              True\n",
       "TI_MI              True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check types as well.\n",
    "test.dtypes == train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make sure that categorical values are represented in the same way in the training and test set \n",
    "# before we apply machine learning algorithms; if training and test sets have different numbers\n",
    "# of features (or even if the numbers are the same, they must be equal columns) \n",
    "# and we can't apply the model we learned on the training set to the test set anymore.\n",
    "# Therefore, we need to concatnenate before using get_dummies.\n",
    "border = len(train)\n",
    "comb = pd.concat([train,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comb.drop('inspector_name', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert object type columns to dummies.\n",
    "## ORIGINAL\n",
    "df_dummy = pd.get_dummies(comb)\n",
    "\n",
    "## REMOVE INSPECTOR NAME\n",
    "#df_dummy = pd.get_dummies(comb,columns = list(train.dtypes[train.dtypes == 'object'].index).remove('inspector_name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double check if there is any missing values.\n",
    "df_dummy.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For modeling, split train and test as before.\n",
    "\n",
    "X_train = df_dummy.iloc[:border,:]\n",
    "X_test = df_dummy.iloc[border:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set dim: (250306, 717) , Test set dim: (61001, 717)\n"
     ]
    }
   ],
   "source": [
    "print('Training set dim:',X_train.shape, ',', 'Test set dim:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-f45f0be9c658>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mselect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRFE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_features_to_select\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mselect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_train_sel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_test_sel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/feature_selection/rfe.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \"\"\"\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/feature_selection/rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, step_score)\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fitting estimator with %d features.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;31m# Get coefs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    325\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 327\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "select = RFE(RandomForestClassifier(n_estimators=300, random_state=1),n_features_to_select = 500)\n",
    "select.fit(X_train,y)\n",
    "X_train_sel = select.transform(X_train)\n",
    "X_test_sel = select.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_sel.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from matplotlib import pyplot as plt\n",
    "#import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cc = Counter(y)\n",
    "#print('training set %:',cc[0]/len(train)*100, 'test set %:',cc[1]/len(train)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(10,5))\n",
    "#sns.countplot(data=y)\n",
    "#ax = plt.gca()\n",
    "#ax.set_xticklabels(['non-compliant','compliant']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph and the Counter function are showing that the data is highly imbalanced. Most of data is 0, which means as a measure of accuracy, auc_roc method is more encouraged to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#y_temp = y.fillna(0.0)\n",
    "\n",
    "#temp_df = pd.concat([comb.iloc[:border,:],y_temp])\n",
    "#temp_df.corr()\n",
    "\n",
    "#plt.figure(figsize=(15,5))\n",
    "#sns.heatmap(temp_df.corr(),annot=True,linewidth=3,linecolor='yellow');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 State (mailing address state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Violation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Fine Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.decomposition import PCA\n",
    "#from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prior to PCA, scaling is crucial so that each feature has unit variance using StandardScaler\n",
    "\n",
    "#scaler = StandardScaler().fit(X_train)\n",
    "#X_train = scaler.transform(X_train)\n",
    "#X_test = scaler.transform(X_test)\n",
    "\n",
    "# Keep the half principal components of the data.\n",
    "\n",
    "#pca = PCA(n_components = int(len(X_train)**(0.5)))\n",
    "\n",
    "# Fit PCA model to data and transform first half of the principal components\n",
    "\n",
    "#pca_train = pca.fit_transform(X_train)\n",
    "#pca_test = pca.transform(X_test)\n",
    "#print(\"Original Train shape: {}\".format(str(X_train.shape)))\n",
    "#print(\"Reduced Train shape: {}\".format(str(pca_train.shape)))\n",
    "\n",
    "#print(\"Original Test shape: {}\".format(str(X_test.shape)))\n",
    "#print(\"Reduced Test shape: {}\".format(str(pca_test.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, learning_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(10, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=1)\n",
    "\n",
    "param = {\n",
    "            'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "            'penalty':['l1','l2'],\n",
    "            'class_weight':['balanced',{1:2},{1:3}]\n",
    "        }\n",
    "\n",
    "lrCV = GridSearchCV(lr, param_grid=param, cv=kfold, verbose=True, n_jobs=-1, scoring='roc_auc')\n",
    "#lrCV.fit(pca_train,y)\n",
    "lrCV.fit(X_train_sel,y)\n",
    "lrCV_best = lrCV.best_estimator_\n",
    "print(lrCV.best_params_)\n",
    "\n",
    "# CV = 10 (ORIGINAL WITHOUT INSPECTOR NAME) - preserved in original file.\n",
    "# * {'C':0.001, 'penalty':'l1','class_weight':{1:2}}\n",
    "# ** {'C': 0.001, 'class_weight': {1: 2}, 'penalty': 'l1'} - 0.8642844\n",
    "\n",
    "# CV = 10 (SELECTFROMMODEL)\n",
    "# * {'C': 0.001, 'class_weight': {1: 2}, 'penalty': 'l1'} - 0.86427307750706317 (한번더 조절해야할듯)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lrCV.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame(lrCV.predict(X_test_sel), index = test_id)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_summary = result.apply(pd.value_counts)\n",
    "result_summary['%'] = result_summary.apply(lambda x:x/np.sum(result_summary[0])*100)\n",
    "result_summary.columns = ['count','%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 6. Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import visualization libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lcplot(model,X,y,title,train_sizes=np.linspace(0.1,1.0,5)):\n",
    "    \n",
    "    train_sizes, train_scores, test_scores = learning_curve(model,X,y,cv=kfold,n_jobs=1,train_sizes=train_sizes,pre_dispatch=8)\n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores,axis=1)\n",
    "    train_scores_std = np.std(train_scores,axis=1)\n",
    "    \n",
    "    test_scores_mean = np.mean(test_scores,axis=1)\n",
    "    test_scores_std = np.std(test_scores,axis=1)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Training size\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                    train_scores_mean + train_scores_std, alpha = 0.1, color='r')\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                    test_scores_mean + test_scores_std, alpha = 0.1, color='g')\n",
    "    plt.plot(train_sizes,train_scores_mean, 'o-', color='r', label='Training Score')\n",
    "    plt.plot(train_sizes,test_scores_mean, 'o-', color='g', label='CV score')\n",
    "    plt.legend(loc='best')\n",
    "    return plt\n",
    "\n",
    "g = lcplot(lrCV.best_estimator_,X_train,y,\"Logistic Regression\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-machine-learning",
   "graded_item_id": "nNS8l",
   "launcher_item_id": "yWWk7",
   "part_id": "w8BSS"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
